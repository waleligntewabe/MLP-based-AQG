{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Chunk Level MLP Based QG Progress 3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "WGXMpIfNdQt0",
        "byp7jrlY9fLk",
        "5BPvIf_BHmVP",
        "c1d_2wMk28Wa",
        "cDVpdyav5rEP",
        "owSSHj7POEVn",
        "ptvRQqWpJ9hZ",
        "a24UuxvNHuJM",
        "IASl9u74I6C-",
        "NmcE-D8E0jxC",
        "jygBEfCc6Mn-",
        "SUWdHOBIENag"
      ],
      "authorship_tag": "ABX9TyNQW2pQI0KUw2gKWMGSdNiP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waleligntewabe/MLP-based-AQG/blob/main/Copy_of_Chunk_Level_MLP_Based_QG_Progress_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGXMpIfNdQt0"
      },
      "source": [
        "# **Templated Based Q**G"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ruf5qO0dUSW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07b6c6f8-8059-408a-d48f-a21d54dd9aa4"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "#doc = nlp(\"Application of Template Based Question Generation for Study Materials\")\n",
        "doc = nlp(\"Ethiopia is African country has its own alphabet\")\n",
        "   \n",
        "# Definie functions that generate Question based on the given Template\n",
        "\n",
        "Q=dePnsubj= dePROOT=dePadvel=dePagent=dePdet=dePadvmod=dePprep=dePpobj=dePmark=dePadvcl=dePconj=dePdobj=dePdep=dePamod=dePprt=dePccomp=dePxcomp=dePrelcl=dePcc=dePappos=dePpcomp=dePposs=\"\"\n",
        "A=dePcompound=dePccomp=dePrelcl=dePnsubj=dePacl=dePcc=dePposs=temp=dePaux=dePappos=dePpcomp=dePprt=dePnpadvmod=\"\"\n",
        "\n",
        "#..............Select Sentence..........................................\n",
        "  \n",
        "#..............Catagorize sentence in to NER, SRL, Dependency...........\n",
        "\n",
        "#..............SRL based Generate Question .............................\n",
        "\n",
        "# Python3 code to iterate over a list \n",
        "\n",
        "#..............Dependency based Generate Question ......................\n",
        "\n",
        "a=b=c=d=e=f=g=h=i=j=k=l=m=n=o=p=q=r=s=t=u=v=w=x=y=z=0\n",
        "\n",
        "dePnsubj1=dePnsubj2=dePprep1=dePprep2=dePdet1=dePdet2=dePamod1=dePamod2=dePpobj1=dePpobj2=dePamod1=dePamod2=dePpobj1=\"\"\n",
        "dePpobj2=dePadvmod1=dePadvmod2=dePadvcl1=dePadvcl2=dePconj1=dePconj2=dePmark1=dePmark2=dePagent1=dePagent2=dePROOT1=\"\"\n",
        "dePROOT2=dePadvel1=dePadvel2=dePdobj1=dePdobj2=dePcompound1=dePcompound2=dePappos1=dePappos2=dePpcomp1=dePpcomp2=\"\"\n",
        "dePprt1=dePprt2=dePdep1=dePdep2=dePnpadvmod1= dePnpadvmod2=dePrelcl1=dePrelcl2=dePaux1=dePaux2=dePccomp1=dePccomp2=\"\"\n",
        "dePxcomp1=dePacl1=dePcc1=dePcc2=dePposs1=dePprep3=dePpobj3=dePamod3=\"\"\n",
        "\n",
        "for token in doc:\n",
        "       \n",
        "    if(token.dep_==\"nsubj\"):\n",
        "        dePnsubj=token.text\n",
        "        if (a==0):\n",
        "            dePnsubj1=dePnsubj\n",
        "            a=a+1\n",
        "        elif(a==1):\n",
        "            dePnsubj2=dePnsubj\n",
        "            a=a+1\n",
        "    elif(token.dep_==\"prep\"):\n",
        "        dePprep=token.text\n",
        "        if (b==0):\n",
        "            dePprep1=dePprep\n",
        "            b=b+1\n",
        "        elif(b==1):\n",
        "            dePprep2=dePprep\n",
        "            b=b+1\n",
        "        elif(b==2):\n",
        "            dePprep3=dePprep\n",
        "            b=b+1\n",
        "    elif(token.dep_==\"det\"):\n",
        "        dePdet=token.text\n",
        "        if (c==0):\n",
        "            dePdet1=dePdet\n",
        "            c=c+1\n",
        "        elif(c==1):\n",
        "            dePdet2=dePdet\n",
        "            c=c+1\n",
        "    elif(token.dep_==\"amod\"):\n",
        "        dePamod=token.text\n",
        "        if (d==0):\n",
        "            dePamod1=dePamod\n",
        "            d=d+1\n",
        "        elif(d==1):\n",
        "            dePamod2=dePamod\n",
        "            d=d+1\n",
        "        elif(d==2):\n",
        "            dePamod3=dePamod\n",
        "            d=d+1\n",
        "    elif( token.dep_==\"pobj\"):\n",
        "        dePpobj=token.text\n",
        "        if (e==0):\n",
        "            dePpobj1=dePpobj\n",
        "            e=e+1\n",
        "        elif(e==1):\n",
        "            dePpobj2=dePpobj\n",
        "            e=e+1 \n",
        "        elif(e==2):\n",
        "            dePpobj3=dePpobj\n",
        "            e=e+1  \n",
        "    elif(token.dep_==\"advmod\"):\n",
        "        dePadvmod=token.text\n",
        "        if (f==0):\n",
        "            dePadvmod1=dePadvmod\n",
        "            f=f+1\n",
        "        elif(f==1):\n",
        "            dePadvmod2=dePadvmod\n",
        "            f=f+1 \n",
        "    elif(token.dep_==\"advcl\"):\n",
        "        dePadvcl=token.text\n",
        "        if (g==0):\n",
        "            dePadvcl1=dePadvcl\n",
        "            g=g+1\n",
        "        elif(g==1):\n",
        "            dePadvcl2=dePadvcl\n",
        "            g=g+1 \n",
        "    elif(token.dep_==\"conj\"):\n",
        "        dePconj=token.text\n",
        "        if (h==0):\n",
        "            dePconj1=dePconj\n",
        "            h=h+1\n",
        "        elif(h==1):\n",
        "            dePconj2=dePconj\n",
        "            h=h+1 \n",
        "    elif(token.dep_==\"mark\"):\n",
        "        dePmark=token.text\n",
        "        if (i==0):\n",
        "            dePmark1=dePmark\n",
        "            i=i+1\n",
        "        elif(i==1):\n",
        "            dePmark2=dePmark\n",
        "            i=i+1 \n",
        "    elif(token.dep_==\"agent\"):\n",
        "        dePagent=token.text\n",
        "        if (j==0):\n",
        "            dePagent1=dePagent\n",
        "            j=j+1\n",
        "        elif(j==1):\n",
        "            dePagent2=dePagent\n",
        "            j=j+1 \n",
        "    elif(token.dep_==\"ROOT\"):\n",
        "        dePROOT=token.text\n",
        "        if (k==0):\n",
        "            dePROOT1=dePROOT\n",
        "            k=k+1\n",
        "        elif(k==1):\n",
        "            dePROOT2=dePROOT\n",
        "            k=k+1 \n",
        "    elif(token.dep_==\"advel\"):\n",
        "        dePadvel=token.text\n",
        "        if (l==0):\n",
        "            dePadvel1=dePadvel\n",
        "            l=l+1\n",
        "        elif(l==1):\n",
        "            dePadvel2=dePadvel\n",
        "            l=l+1 \n",
        "    elif(token.dep_==\"dobj\"):\n",
        "        dePdobj=token.text\n",
        "        if (m==0):\n",
        "            dePdobj1=dePdobj\n",
        "            m=m+1\n",
        "        elif(m==1):\n",
        "            dePdobj2=dePdobj\n",
        "            m=m+1 \n",
        "    elif(token.dep_==\"compound\"):\n",
        "        dePcompound=token.text\n",
        "        if (n==0):\n",
        "            dePcompound1=dePcompound\n",
        "            n=n+1\n",
        "        elif(n==1):\n",
        "            dePcompound2=dePcompound\n",
        "            n=n+1 \n",
        "    elif(token.dep_==\"appos\"):\n",
        "        dePappos=token.text\n",
        "        if (o==0):\n",
        "            dePappos1=dePappos\n",
        "            o=o+1\n",
        "        elif(o==1):\n",
        "            dePappos2=dePappos\n",
        "            o=o+1 \n",
        "    elif(token.dep_==\"pcomp\"):\n",
        "        dePpcomp=token.text\n",
        "        if (p==0):\n",
        "            dePpcomp1=dePpcomp\n",
        "            p=p+1\n",
        "        elif(p==1):\n",
        "            dePpcomp2=dePpcomp\n",
        "            p=p+1 \n",
        "    elif(token.dep_==\"prt\"):\n",
        "        dePprt=token.text\n",
        "        if (q==0):\n",
        "            dePprt1=dePprt\n",
        "            q=q+1\n",
        "        elif(q==1):\n",
        "            dePprt2=dePprt\n",
        "            q=q+1 \n",
        "    elif(token.dep_==\"dep\"):\n",
        "        dePdep=token.text\n",
        "        if (r==0):\n",
        "            dePdep1=dePdep\n",
        "            r=r+1\n",
        "        elif(r==1):\n",
        "            dePdep2=dePdep\n",
        "            r=r+1 \n",
        "    elif(token.dep_==\"npadvmod\"):\n",
        "        dePnpadvmod=token.text \n",
        "        if (s==0):\n",
        "            dePnpadvmod1=dePnpadvmod\n",
        "            s=s+1\n",
        "        elif(s==1):\n",
        "            dePnpadvmod2=dePnpadvmod\n",
        "            s=s+1 \n",
        "    elif(token.dep_==\"relcl\"):\n",
        "        dePrelcl=token.text\n",
        "        if (t==0):\n",
        "            dePrelcl1=dePprep\n",
        "            t=t+1\n",
        "        elif(t==1):\n",
        "            dePrelcl2=dePprep\n",
        "            t=t+1\n",
        "    elif(token.dep_==\"relcl\"):\n",
        "        dePaux=token.text\n",
        "        if (u==0):\n",
        "            dePaux1=dePaux\n",
        "            u=u+1\n",
        "        elif(u==1):\n",
        "            dePaux2=dePaux\n",
        "            u=u+1\n",
        "    elif(token.dep_==\"ccomp\"):\n",
        "        dePccomp=token.text\n",
        "        if (v==0):\n",
        "            dePccomp1=dePccomp\n",
        "            v=v+1\n",
        "        elif(v==1):\n",
        "            dePccomp2=dePccomp\n",
        "            v=v+1\n",
        "    elif(token.dep_==\"xcomp\"):\n",
        "        dePxcomp=token.text\n",
        "        if (w==0):\n",
        "            dePxcomp1=dePxcomp\n",
        "            w=w+1\n",
        "        elif(w==1):\n",
        "            dePxcomp2=dePxcomp\n",
        "            w=w+1\n",
        "    elif(token.dep_==\"acl\"):\n",
        "        dePac=token.text\n",
        "        if (x==0):\n",
        "            dePacl1=dePac\n",
        "            x=x+1\n",
        "        elif(x==1):\n",
        "            dePacl2=dePac\n",
        "            x=x+1\n",
        "    elif(token.dep_==\"acl\"):\n",
        "        dePcc=token.text\n",
        "        if (y==0):\n",
        "            dePcc1=dePcc\n",
        "            y=y+1\n",
        "        elif(y==1):\n",
        "            dePcc2=dePcc\n",
        "            y=y+1\n",
        "    elif(token.dep_==\"poss\"):\n",
        "        dePposs=token.text\n",
        "        if (z==0):\n",
        "            dePposs1=dePposs\n",
        "            z=z+1\n",
        "        elif(z==1):\n",
        "            dePposs2=dePposs\n",
        "            z=z+1\n",
        "    else:\n",
        "        temp\n",
        "\n",
        "#\"\"\"\n",
        "#..............................................................................................\n",
        "def MADV1():\n",
        "    Q=\"What \"+\"does \"+dePcompound1+\" \"+\"do\"+dePmark1+ \" \"+ dePnsubj1+\" \"+ dePadvcl1+\"?\"\n",
        "    A=dePcompound1+\" \"+dePconj1+\" \"+dePprep1+\" \"+dePdet1+\" \"+dePpobj1+\" \"+dePprep2+\" \"+dePpobj2\n",
        "    print(\"Question1=\"+Q)\n",
        "    print(\"Answer1=\"+A) \n",
        "def MADV2():\n",
        "    Q=\"Who \"+dePROOT1+\" \"+dePprep1+\" \"+dePdet1+\" \"+ dePpobj1+ \" when \"+ dePadvcl1+\" \"+dePadvmod1+\"?\"\n",
        "    A=dePnsubj1+\" \"+dePROOT1+\" \"+\" \"+dePprep1+\" \"+dePdet1+\" \"+dePpobj1\n",
        "    print(\"Question2=\"+Q)\n",
        "    print(\"Answer2=\"+A)\n",
        "def MADV3():\n",
        "    Q=\"What is it that \"+dePnsubj1+ \" \"+ dePROOT1+\" when \"+dePadvcl1+\" \"+dePagent1+\" \"+dePdet1+\" \"+dePpobj1+\"?\"\n",
        "    A=dePnsubj1+\" \"+dePROOT1+\" \"+dePdet1+\" \"+dePdobj1+\" \"+dePprep1+\" \"+dePdet1+\" \"+dePpobj2\n",
        "    print(\"Question3=\"+Q)\n",
        "    print(\"Answer3=\"+A)\n",
        "def MADV4():\n",
        "    Q=\"What happens \"+\" when \"+dePadvcl1+\" \"+dePagent1+\" \"+dePdet1+\" \"+ dePpobj1+\"?\"\n",
        "    A=dePnsubj1+\" \"+dePROOT1+\" \"+dePdet1+\" \"+dePdobj1+\" \"+dePprep1+\" \"+dePdet1+\" \"+dePpobj2\n",
        "    print(\"Question4=\"+Q)\n",
        "    print(\"Answer4=\"+A)\n",
        "def MADV5():\n",
        "    Q=\"When does \"+dePnsubj1+\" \"+dePROOT1+\" \"+ dePdet1+\" \"+dePdobj1+\" \"+dePprep1+\" \"+dePdet1+\" \"+dePpobj2+\"?\"\n",
        "    A=\"When \"+ dePnsubj1+\" \"+ dePadvcl1+\" \"+dePagent1+\" \"+dePdet1+\" \"+dePpobj1 \n",
        "    print(\"Question5=\"+Q)\n",
        "    print(\"Answer5=\"+A)\n",
        "#\"\"\"\n",
        "\n",
        "#..............................................................................................\n",
        "def MMNR1():    \n",
        "    Q= \"Who \" + dePROOT1  +\" \"+ dePdet1 +\" \" + dePamod1 +\" \" + dePdobj1 +\" \" + dePprep1 + \" \" + dePdet1 +\" \" + dePpobj1 + \"?\"\n",
        "    A=dePnsubj1\n",
        "    print(\"Question1=\"+Q)\n",
        "    print(\"Answer1=\"+A)\n",
        "\n",
        "def MMNR2():\n",
        "    Q=\"How \" + \"does \" + dePnsubj1 + \" \"+ dePROOT1 +\" \"+ dePdet1 +\" \"+ dePdobj1+\"?\"\n",
        "    A=dePprep1+ \" \"+ dePdet1 +\" \"+ dePpobj1+ \" \" + dePnsubj1 +\" \"+ dePrelcl1 +\" \"+ dePdobj1 +\" \"+ dePaux1 +\" \"+ dePxcomp1 +\" \"+ dePdobj2\n",
        "    print(\"Question2=\"+Q)\n",
        "    print(\"Answer2=\"+A)\n",
        "\n",
        "def MMNR3():\n",
        "    Q=\"How \" + \"does \" + dePnsubj1 + \" \"+ dePROOT1 +\" \"+ dePdet1 +\" \"+ dePdobj1+\"?\"\n",
        "    A=dePprep1+ \" \" +dePdet2 +\" \"+ dePpobj1\n",
        "    print(\"Question3=\"+Q)\n",
        "    print(\"Answer3=\"+A)\n",
        "#..................................................................................\n",
        "\n",
        "\n",
        "def MMLOC1():\n",
        "    Q=\"What \"+\"does \" +dePnsubj1+\" do \" + dePprep1+\" \"+ dePdet1+\" \"+dePamod1+\" \"+ dePpobj1+\" \"+dePamod2+\" \"+dePprep2+\" \"+dePpobj2+\"?\"\n",
        "    A=dePnsubj1+\" \"+ dePROOT1+\" \"+dePdobj1 \n",
        "    print(\"Question1=\"+Q)\n",
        "    print(\"Answer=\"+A)\n",
        "def MMLOC2():\n",
        "    Q=\"What \"+\"does \" +dePnsubj1+\" do \" +dePprep1+\" \"+dePdet2+\" \"+dePamod1+\" \"+dePpobj1+\"?\"\n",
        "    A=dePnsubj1+\" \"+ dePrelcl1+\" \"+dePdet2+\" \"+dePROOT1 \n",
        "    print(\"Question2=\"+Q)\n",
        "    print(\"Answer=\"+A)\n",
        "def MMLOC3():\n",
        "    Q=\"Who \"+ dePROOT1+\" \"+dePdobj1+\" \"+dePadvmod1+\" \"+dePprep1+\" \"+dePpobj1+\" \"+dePccomp1+\" \"+dePpobj2+\"?\"\n",
        "    A=dePnsubj+\" does\"\n",
        "    print(\"Question3=\"+Q)\n",
        "    print(\"Answer=\"+A)\n",
        "def MMLOC4():\n",
        "    Q=\"What \"+ \"does \"+dePnsubj1+\" \"+dePrelcl1+\" \"+\" in \" +\" the \" +dePROOT1+\"?\"\n",
        "    A=dePnsubj1+\" \"+dePrelcl1+\" \" + dePdet1+\" \"+ dePdobj1+\" \"+dePacl1+\" \"+dePprep1+\" \"+dePdet2+\" \"+dePpobj1+\" \"+dePcc1+\" \"+dePconj1+dePdobj2\n",
        "    print(\"Question4=\"+Q)\n",
        "    print(\"Answer=\"+A)\n",
        "def MMLOC5():\n",
        "    Q=\"What \"+ \" happens \"+dePprep1+\" \"+dePposs1+\" \"+dePpobj1+\"?\"\n",
        "    A=dePposs1+\" \"+dePamod1+\" \"+dePnsubj1+\" \"+dePROOT1+\" \"+dePdet1+\" \"+dePdobj1\n",
        "    print(\"Question5=\"+Q)\n",
        "    print(\"Answer=\"+A)\n",
        "def MMLOC6():\n",
        "    Q=\"Where does \"+ dePnsubj1+\" \"+dePconj1+\" \"+dePdobj1+\" \"+\"?\"\n",
        "    A=dePprep2+\" \"+dePdet2+\" \"+dePamod2+\" \"+dePpobj2+\" \"+dePamod3+\" \"+dePprep3+\" \"+dePpobj3\n",
        "    print(\"Question6=\"+Q)\n",
        "    print(\"Answer=\"+A)\n",
        "\n",
        "#..................................................................................\n",
        "def MTMP1():\n",
        "    Q=\"What \"+ \" does \"+dePnsubj1+\" do \"+dePdet1+\" \"+dePamod1+ \" \"+dePnsubj2+\" \"+dePadvmod1+\" \"+dePrelcl+\"?\"\n",
        "    A=dePnsubj+\" \"+dePROOT1+\" \"+dePdet1+\" \"+dePamod1+\" \" + dePnsubj2\n",
        "    \n",
        "    print(\"Question1=\"+Q)\n",
        "    print(\"Answer=\"+A)\n",
        "def MTMP2():\n",
        "    Q=\"Who \"+ dePROOT1+\" \"+dePdet1+\" \"+dePamod1+ \" \"+dePnsubj1+\" \"+dePadvmod1+\" \"+dePrelcl1+\"?\"\n",
        "    A=dePnsubj1\n",
        "    \n",
        "    print(\"Question2=\"+Q)\n",
        "    print(\"Answer=\"+A)\n",
        "def MTMP3():\n",
        "    Q=\"What does \"+ dePdet1+\" \"+dePnsubj1+\" \"+dePappos1+ \" \"+dePROOT1+\" \"+dePprep1+\" \"+dePdet2+\" \"+dePpcomp1+\" \"+dePnsubj2+\" \"+dePadvcl+\" \"+dePprt+\"?\"\n",
        "    A=dePdet1 + \" \"+ dePnsubj1 +\" \" + dePappos1 +\" \" + dePROOT1 +\" \" + dePdobj1\n",
        "    \n",
        "    print(\"Question2=\"+Q)\n",
        "    print(\"Answer=\"+A)\n",
        "def MTMP4():\n",
        "    Q=\"What does \" +dePnsubj1+\" \"+dePROOT1+ \" \"+dePdep1+\" \"+dePprep1+\" \"+dePdet1+\" \"+dePpobj1+\"?\"\n",
        "    A=dePnsubj1 +\" \" + dePROOT1 +\" \" + dePnpadvmod1\n",
        "    \n",
        "    print(\"Question2=\"+Q)\n",
        "    print(\"Answer=\"+A)\n",
        "#..................................................................................\n",
        "        \n",
        "def ARGU1():\n",
        "    Q=\"Who \" +dePROOT1+ \" \"+ dePnsubj1 +\"?\"\n",
        "    A=dePnsubj1 +\" \" + dePROOT1 +\" \" + dePnpadvmod1\n",
        "    print(\"MTMPQ2=\"+Q)\n",
        "    print(\"A=\"+A)\n",
        "#..................................................................................\n",
        "\n",
        "#..................................................................................\n",
        "        \n",
        "def DCNJ1():\n",
        "    Q=\"What happens when \" +dePnsubj1+ \" \"+ dePROOT1+\" \"+ dePposs1+\" \"+ dePdobj1 +\" \" +dePprep1 + \" \" +dePdet1+\" \"+ dePpobj1 +\" \"+ dePprep+\" \" +dePdet +\" \"+ dePpobj +\" \"+ dePcc+\" \"+dePconj+\" \"+dePdet+\" \"+dePdobj+\"?\"\n",
        "    A=dePnsubj1 +\" \" + dePROOT1 +\" \" + dePdobj1+\" \"+dePprep1+\" \"+dePdet1+\" \"+dePdobj2+\" \"+dePdobj2+\" \"+dePcc2 +\" \"+ dePconj2+\" \"+dePdet2+\" \"+dePdobj\n",
        "    \n",
        "    print(\"MTMPQ2=\"+Q)\n",
        "    print(\"A=\"+A)\n",
        "#..................................................................................\n",
        "\n",
        "\n",
        "print(\"Part One: Adverbials Argument Modifiers\")\n",
        "MADV1()\n",
        "MADV2()\n",
        "MADV3()\n",
        "MADV4()\n",
        "MADV5()\n",
        "\n",
        "print(\"Part Two: Manner Markers Argument Modifiers\")\n",
        "MMNR1()\n",
        "MMNR2()\n",
        "MMNR3()\n",
        "\n",
        "print(\"Part Three: Locatives Argument Modifiers\")\n",
        "MMLOC1()\n",
        "MMLOC2()\n",
        "MMLOC3()\n",
        "MMLOC4()\n",
        "MMLOC5()\n",
        "MMLOC6()\n",
        "\n",
        "print(\"Part Four: Temporal Markers Argument Modifiers\")\n",
        "MTMP1()\n",
        "MTMP2()\n",
        "MTMP3()\n",
        "MTMP4()\n",
        "\n",
        "print( \"Part 5\")\n",
        "ARGU1()\n",
        "print( \"Part 6\")\n",
        "DCNJ1()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Part One: Adverbials Argument Modifiers\n",
            "Question1=What does  do Ethiopia ?\n",
            "Answer1=      \n",
            "Question2=Who is    when  ?\n",
            "Answer2=Ethiopia is    \n",
            "Question3=What is it that Ethiopia is when    ?\n",
            "Answer3=Ethiopia is  alphabet   \n",
            "Question4=What happens  when    ?\n",
            "Answer4=Ethiopia is  alphabet   \n",
            "Question5=When does Ethiopia is  alphabet   ?\n",
            "Answer5=When Ethiopia    \n",
            "Part Two: Manner Markers Argument Modifiers\n",
            "Question1=Who is  African alphabet   ?\n",
            "Answer1=Ethiopia\n",
            "Question2=How does Ethiopia is  alphabet?\n",
            "Answer2=   Ethiopia  alphabet   \n",
            "Question3=How does Ethiopia is  alphabet?\n",
            "Answer3=  \n",
            "Part Three: Locatives Argument Modifiers\n",
            "Question1=What does Ethiopia do   African  own  ?\n",
            "Answer=Ethiopia is alphabet\n",
            "Question2=What does Ethiopia do   African ?\n",
            "Answer=Ethiopia   is\n",
            "Question3=Who is alphabet    has ?\n",
            "Answer=Ethiopia does\n",
            "Question4=What does Ethiopia   in  the is?\n",
            "Answer=Ethiopia   alphabet      \n",
            "Question5=What  happens  its ?\n",
            "Answer=its African Ethiopia is  alphabet\n",
            "Question6=Where does Ethiopia  alphabet ?\n",
            "Answer=  own    \n",
            "Part Four: Temporal Markers Argument Modifiers\n",
            "Question1=What  does Ethiopia do  African   ?\n",
            "Answer=Ethiopia is  African \n",
            "Question2=Who is  African Ethiopia  ?\n",
            "Answer=Ethiopia\n",
            "Question2=What does  Ethiopia  is      ?\n",
            "Answer= Ethiopia  is alphabet\n",
            "Question2=What does Ethiopia is    ?\n",
            "Answer=Ethiopia is \n",
            "Part 5\n",
            "MTMPQ2=Who is Ethiopia?\n",
            "A=Ethiopia is \n",
            "Part 6\n",
            "MTMPQ2=What happens when Ethiopia is its alphabet          alphabet?\n",
            "A=Ethiopia is alphabet        alphabet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbGYGbPOdG7k"
      },
      "source": [
        "#**Phrase Level MLP Based QG**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byp7jrlY9fLk"
      },
      "source": [
        "## **1 Import, preprocessing and vectorization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxBVL6pbqdVS"
      },
      "source": [
        " **1. Import Training and Testing Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PysGDSi4kGhA",
        "outputId": "c0d36bc7-e627-404d-e0c4-54ff2315d8ff"
      },
      "source": [
        "import re\n",
        "import spacy\n",
        "import csv\n",
        "\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkhnA09Qrfvs"
      },
      "source": [
        "**A. Import Sentence Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "WD8O2WakkM39",
        "outputId": "5fb6c325-181c-42d5-a00a-f0ee8cf095da"
      },
      "source": [
        "#Upload the dataset from local storage into colab\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "#reading the dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2f22afca-1698-45c0-bf87-47966daa2844\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2f22afca-1698-45c0-bf87-47966daa2844\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 1000 SentPhrase1.csv to 1000 SentPhrase1.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1000 SentPhrase1.csv': b'NP1,PP1,NP2,VP1,PP2,NP3,AA,AA,AA\\r\\nNP1,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,VP2,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,PP2,NP3,VP2,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nADJP1,PP1,NP1,VP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,PP1,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,PP1,ADVP1,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,NP3,PP1,NP4,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,ADJP1,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nVP1,NP1,VP2,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,NP3,PP1,NP4,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,NP3,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,NP3,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,NP3,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,VP2,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,VP2,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,PP1,NP2,VP2,NP3,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,VP2,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,PP2,VP2,NP3,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,VP2,NP2,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,ADJP1,PP2,NP3,AA,AA\\r\\nNP1,VP1,NP2,VP2,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nVP1,NP1,VP2,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nVP1,PP1,ADVP1,PP2,NP1,VP2,NP2,AA,AA\\r\\nNP1,VP1,PP1,ADVP1,PP2,NP2,VP2,ADJP1,AA\\r\\nNP1,VP1,NP2,NP3,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,NP3,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,VP2,NP3,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,NP3,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,NP3,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,VP2,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,ADJP1,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,VP2,NP3,AA,AA,AA\\r\\nNP1,VP1,ADJP1,VP2,PP1,NP2,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,VP2,PP2,NP3,AA,AA\\r\\nNP1,VP1,PP1,VP2,NP2,PP2,AA,NP4,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,VP2,NP3,AA,AA,AA\\r\\nNP1,VP1,NP2,ADJP1,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,ADJP1,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,ADJP2,AA,AA,AA,AA,AA\\r\\nNP1,NP2,VP1,NP3,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,NP2,VP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,PP2,NP3,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,PP2,NP4,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nADVP1,NP1,VP1,ADJP1,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nADVP1,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,VP2,NP2,PP2,NP3,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,VP2,NP2,PP2,NP3,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,VP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,VP2,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,VP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,VP2,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,ADJP1,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,VP2,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nVP1,NP1,VP2,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,VP2,NP2,PP2,AA,NP4,AA\\r\\nNP1,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,ADJP1,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nVP1,NP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,NP3,PP1,NP4,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,VP2,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nADVP1,VP1,ADVP2,NP1,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nVP1,NP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,PP1,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,VP2,ADJP1,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,VP2,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,ADJP1,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,ADJP1,PP1,NP2,PP2,NP3,VP1,NP4,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,PP2,NP4,AA,AA\\r\\nNP1,VP1,ADJP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,PP2,NP3,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,ADVP1,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,ADJP1,VP2,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,ADJP1,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nADVP1,NP1,VP1,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,NP3,PP1,NP4,AA,AA\\r\\nNP1,VP1,PP1,VP2,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,VP2,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,ADJP1,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,NP3,PP1,NP4,AA,AA\\r\\nNP1,VP1,NP2,VP2,NP3,PP1,NP4,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,ADJP1,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,VP2,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,ADJP1,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,VP2,AA,AA,AA,AA\\r\\nVP1,PP1,NP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,VP2,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,VP2,NP2,ADJP1,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,ADJP1,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,PP1,VP2,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nADVP1,NP1,VP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,PP2,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nVP1,NP1,VP2,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,ADJP1,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,PP2,NP3,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nADJP1,VP1,NP1,VP2,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,VP2,NP4,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,ADJP1,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,VP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,ADJP1,PP1,NP3,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nVP1,PP1,NP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,VP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,NP3,ADVP1,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,VP2,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,ADJP1,PP1,NP3,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,NP3,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,VP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nVP1,NP1,VP2,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,ADVP1,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,ADVP1,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,VP2,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,VP2,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nADVP1,NP1,VP1,NP2,PP1,ADJP1,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,ADJP2,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,NP2,VP2,PP2,NP3,AA\\r\\nNP1,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,VP2,PP2,ADVP1,AA\\r\\nNP1,VP1,NP2,PP1,VP2,ADVP1,AA,AA,AA\\r\\nNP1,VP1,NP2,NP3,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,PP2,NP3,AA,AA,AA\\r\\nVP1,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,AA,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nVP1,NP1,VP2,NP2,PP1,NP3,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,PP1,NP2,PP2,NP3,AA,AA\\r\\nNP1,VP1,PP1,VP2,PP2,NP2,AA,AA,AA\\r\\nNP1,VP1,VP2,ADJP1,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,PP1,NP3,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,NP3,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nVP1,NP1,VP2,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,VP2,PP1,NP2,PP2,NP3,AA,AA\\r\\nVP1,NP1,VP2,PP1,NP2,PP2,NP3,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nVP1,PP1,NP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,PP2,NP4,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,NP3,AA,AA,AA,AA\\r\\nNP1,ADJP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,ADVP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,PP2,NP3,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,PP2,NP3,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,PP1,ADVP2,PP2,NP2,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,PP2,ADJP1,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,ADVP1,PP1,NP3,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nPP1,NP1,VP1,VP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,NP3,AA,AA,AA,AA\\r\\nADVP1,NP1,VP1,NP2,PP1,NP3,AA,AA,AA\\r\\nVP1,NP1,VP2,PP1,NP2,PP2,NP3,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,VP2,PP1,NP2,PP2,NP3,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,PP2,PP3,NP3,AA,AA\\r\\nNP1,VP1,PP1,NP2,PP2,NP3,AA,AA,AA\\r\\nNP1,NP2,VP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,PP1,NP3,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,ADJP1,AA,AA,AA,AA\\r\\nADJP1,VP1,NP1,VP2,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,NP3,ADJP1,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,ADJP2,PP2,VP2,AA,AA\\r\\nADVP1,NP1,VP1,ADJP1,VP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,NP3,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,NP3,PP1,NP4,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,NP3,VP2,NP4,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,ADJP1,PP1,NP3,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,VP2,NP4,PP2,NP5\\r\\nNP1,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,PP2,NP3,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,ADJP1,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,PP2,NP3,AA,AA,AA,AA\\r\\nNP1,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,PP1,NP3,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,NP2,NP3,AA,AA,AA,AA\\r\\nPP1,NP1,VP1,NP2,PP2,NP3,AA,AA,AA\\r\\nVP1,NP1,VP2,NP2,AA,NP4,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,PP2,NP3,AA,AA,AA\\r\\nVP1,ADVP1,AA,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,VP2,NP4,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,NP2,PP2,NP3,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,NP3,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,NP2,VP1,NP3,AA,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,PP2,NP3,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,ADVP1,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,PP1,NP3,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,NP3,PP1,NP4,AA,AA\\r\\nNP1,VP1,PP1,NP2,PP2,NP3,AA,AA,AA\\r\\nVP1,PP1,NP1,PP2,NP2,AA,AA,AA,AA\\r\\nPP1,NP1,VP1,NP2,NP3,AA,AA,AA,AA\\r\\nADVP1,PP1,NP1,PP2,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,ADJP1,PP1,AA,AA,AA,AA\\r\\nVP1,NP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,AA,AA,AA,AA,AA\\r\\nNP1,NP2,VP1,NP3,PP1,NP4,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nADJP1,VP1,ADVP1,NP1,PP1,NP2,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,NP3,PP1,NP4,AA,AA\\r\\nNP1,VP1,ADJP1,VP2,NP2,PP1,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,PP2,NP3,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,NP4,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,PP2,ADJP1,AA,AA\\r\\nNP1,VP1,PP1,NP2,PP2,NP3,PP3,NP4,AA\\r\\nNP1,VP1,NP2,VP2,PP1,NP3,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,PP1,NP3,AA,AA,AA\\r\\nNP1,VP1,NP2,VP2,NP3,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,NP3,PP2,NP4,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,ADJP1,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nVP1,NP1,PP1,NP2,PP2,NP3,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,PP2,NP4,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,VP2,NP3,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nVP1,PP1,NP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nVP1,NP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nPP1,NP1,VP1,PP2,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,NP2,PP1,NP3,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,PP2,NP4,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,ADJP1,VP2,NP3,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,PP2,NP3,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,VP2,PP2,NP3,AA,AA\\r\\nNP1,PP1,NP2,VP1,NP3,AA,AA,AA,AA\\r\\nNP1,NP2,VP1,ADJP1,PP1,NP3,PP2,NP4,AA\\r\\nNP1,PP1,NP2,VP1,NP3,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,PP2,NP3,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,PP2,NP3,PP3,NP4,ADJP1\\r\\nNP1,VP1,PP1,NP2,PP2,NP3,PP3,NP4,AA\\r\\nNP1,VP1,PP1,NP2,PP2,NP3,AA,AA,AA\\r\\nPP1,NP1,VP1,NP2,PP2,NP3,VP2,PP3,NP4\\r\\nVP1,PP1,NP1,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,VP2,AA,PP1,NP2,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,VP2,NP3,AA,AA,AA\\r\\nNP1,VP1,ADJP1,PP1,NP2,PP2,NP3,VP2,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nPP1,NP1,VP1,PP2,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,NP3,PP2,NP4,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,VP2,PP2,NP4,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,VP2,NP4,AA,AA\\r\\nNP1,VP1,NP2,VP2,NP3,NP4,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,PP2,NP3,PP3,NP4,AA\\r\\nNP1,PP1,NP2,PP2,NP3,VP1,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,PP2,NP3,PP3,NP4,AA\\r\\nPP1,NP1,NP2,PP2,NP3,AA,AA,AA,AA\\r\\nVP1,NP1,VP2,PP1,NP2,PP2,NP3,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,PP2,NP4,PP3,NP5\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,PP2,NP3,AA,AA,AA\\r\\nNP1,VP1,PP1,NP2,PP2,NP3,AA,AA,AA\\r\\nNP1,PP1,VP1,VP2,NP2,AA,ADJP1,AA,AA\\r\\nNP1,PP1,VP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,NP2,PP1,NP3,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,PP1,NP2,VP1,PP2,NP3,PP3,PP4,NP4\\r\\nNP1,PP1,AA,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,PP1,NP3,PP2,NP4,PP3,AA\\r\\nNP1,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nADVP1,NP1,PP1,NP2,VP1,NP3,VP2,NP4,PP2\\r\\nNP1,VP1,PP1,ADJP1,ADJP2,NP2,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,VP2,NP2,NP3,PP1,NP4,AA,AA\\r\\nNP1,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nNP1,NP2,VP1,NP3,PP1,NP4,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,ADVP1,AA,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,ADVP1,AA,AA,AA,AA,AA,AA,AA\\r\\nNP1,ADVP1,AA,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,ADVP1,AA,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nNP1,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nVP1,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-4QpZSvkdGT"
      },
      "source": [
        "St=[]\n",
        "with open(r'1000 SentPhrase1.csv', encoding='latin1') as csvfile:  # This dataset have only list of sentences and it will close the file automatically.\n",
        "    reader = csv.reader(csvfile)\n",
        "    for t in reader: \n",
        "       St.append(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHwUjVhZVFt_"
      },
      "source": [
        "NewPOS_Voc=  ['AA', 'ADJP1','ADJP2','ADJP3','ADJP4','ADJP5', 'ADVP1', 'ADVP2', 'ADVP3', 'ADVP4', 'ADVP5', 'NP1', 'NP2', 'NP3', 'NP4', 'NP5',\n",
        " 'PP1', 'PP2', 'PP3', 'PP4', 'PP5', 'VP1', 'VP2', 'VP3', 'VP4', 'VP5', 'When', 'Which','Why', 'do', 'does', 'did', 'keeps', 'kind', 'many', 'of', 'type', 'what', 'where', 'who']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YZImufFyrn8",
        "outputId": "cb843340-df26-4472-dc7f-fceb2b858fec"
      },
      "source": [
        "z=[]\n",
        "for sent in zip(St):\n",
        "  x=re.sub(\"[']\", \"\" , str(sent))\n",
        "  x=re.sub(\"[,]\", \"\" , str(x))\n",
        "  x=re.sub(\"[[]\", \"\" , str(x))\n",
        "  x=re.sub(\"[]]\", \"\" , str(x))\n",
        "  x=re.sub(\"[)]\", \"\" , str(x))\n",
        "  x=re.sub(\"[(]\", \"\" , str(x))\n",
        "  z.append(x)\n",
        "print(z[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NP1 PP1 NP2 VP1 PP2 NP3 AA AA AA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: FutureWarning: Possible nested set at position 1\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG7LJfadrUjx"
      },
      "source": [
        "**One Hot Encoding for Sentence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGaV4_kpkqiM"
      },
      "source": [
        "SVec=[]\n",
        "for sent in zip(z):\n",
        "    token=word_tokenize(str(sent[0]))\n",
        "    vectorizer = CountVectorizer(min_df=0, lowercase=False)\n",
        "    vectorizer.fit(NewPOS_Voc)\n",
        "    vectorizer.vocabulary_\n",
        "    vectorizer.fit_transform(NewPOS_Voc)\n",
        "    #features=vectorizer.get_feature_names()\n",
        "   \n",
        "    X=vectorizer.transform(token).toarray()\n",
        "\n",
        "    ###############################################################\n",
        "\n",
        "    v_length=360\n",
        "    X = X.reshape(1,v_length)\n",
        "    for i in X: \n",
        "      SVec.append(X)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBS3thOKNMGc"
      },
      "source": [
        "'''\n",
        "#Check the correct vectorization of a sentence\n",
        "testsent=[]\n",
        "testsent=SVec[0]\n",
        "\n",
        "Sent_vector=[]\n",
        "testsent = testsent.reshape(v_length)\n",
        "n=0\n",
        "m=40\n",
        "str(n)\n",
        "str(m)\n",
        "\n",
        "for i in range(9):\n",
        "  Sent_vector.append(testsent[n:m])\n",
        "  n=m\n",
        "  m=m+40\n",
        "#print(Sent_vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjXz16HbfeQr"
      },
      "source": [
        "**B. Import Question Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIJ5G7g_FDtO",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "f9ab139e-4a2a-42d8-8297-1696982d0602"
      },
      "source": [
        "#Upload the dataset from local storage into colab\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "#reading the dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3b15faa5-e1be-4b4c-bae0-3ecf2fda5931\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3b15faa5-e1be-4b4c-bae0-3ecf2fda5931\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 1000 QuesPhrase.csv to 1000 QuesPhrase.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1000 QuesPhrase.csv': b'What,type,of,PP2,NP3,AA,AA,AA,AA\\r\\nWhat,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,kind,of,VP1,VP2,AA,AA,AA,AA\\r\\nwhat,kind,of,NP1,VP1,PP2,VP2,AA,AA\\r\\nWhat,NP2,PP1,NP3,AA,AA,AA,AA,AA\\r\\nWhat,VP1,ADJP1,VP2,AA,AA,AA,AA,AA\\r\\nWhere,do,NP1,VP1,NP2,AA,AA,AA,AA\\r\\nwhat,NP2,PP1,NP3,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,VP2,PP1,ADVP1,AA,AA,AA\\r\\nWhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,kind,of,NP1,VP1,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,NP3,PP1,NP4,AA,AA,AA\\r\\nWhat,NP1,PP1,NP2,VP1,AA,AA,AA,AA\\r\\nwhat,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nwhat,does,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,do,VP2,PP1,NP4,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,kind,of,NP1,VP1,AA,AA,AA,AA\\r\\nWhich,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,NP3,AA,AA,AA,AA,AA\\r\\nwhat,NP2,NP3,AA,AA,AA,AA,AA,AA\\r\\nwhat,NP2,NP3,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,PP1,VP2,NP2,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,VP2,NP2,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,NP2,PP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,ADVP1,PP1,NP2,VP2,NP3,AA,AA\\r\\nwhat,PP1,NP3,VP2,AA,AA,AA,AA,AA\\r\\nWhat,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,NP2,PP2,VP2,NP3,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,ADJP1,VP2,NP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,ADJP1,PP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,VP2,NP3,AA,AA,AA,AA\\r\\nWhat,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP2,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nwhat,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,kind,of,VP1,NP2,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,does,VP1,PP1,ADVP1,PP2,NP1,AA,AA\\r\\nwhat,NP1,VP1,PP1,ADVP1,PP2,NP2,VP2,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,ADJP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,NP3,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,PP1,NP3,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nWhat,does,NP3,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,NP2,NP3,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,PP1,NP3,VP2,AA,AA,AA\\r\\nwhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,PP1,NP2,VP1,ADJP1,AA,AA,AA,AA\\r\\nWhat,NP2,NP3,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,VP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP2,VP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP2,PP1,VP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,VP2,NP2,PP2,NP4,AA,AA\\r\\nwhat,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,PP1,VP2,NP3,AA,AA,AA\\r\\nWhat,NP2,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,ADJP1,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,NP2,VP1,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,does,NP1,NP2,PP1,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nwhat,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nwhat,VP1,PP1,NP2,PP2,NP3,AA,AA,AA\\r\\nWhat,do,NP1,VP1,NP2,PP1,NP3,AA,AA\\r\\nwhat,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nWhat,NP2,PP1,NP3,AA,AA,AA,AA,AA\\r\\nWhat,NP2,PP1,NP3,AA,AA,AA,AA,AA\\r\\nwhat,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,ADVP1,NP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,does,NP1,NP2,PP2,AA,AA,AA,AA\\r\\nWhat,NP2,PP1,NP3,AA,AA,AA,AA,AA\\r\\nWhat,NP2,PP2,NP3,AA,AA,AA,AA,AA\\r\\nwhat,does,NP1,PP1,AA,AA,AA,AA,AA\\r\\nHow,does,NP1,NP2,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,VP2,NP2,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nwhat,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,kind,of,NP1,VP1,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,NP1,VP2,PP1,NP2,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,VP2,AA,AA,AA,AA,AA\\r\\nWhat,NP2,PP1,NP3,AA,AA,AA,AA,AA\\r\\nwhat,does,NP1,PP1,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,type,of,NP1,VP1,AA,AA,AA,AA\\r\\nwhat,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,PP1,NP3,AA,AA,AA\\r\\nWhat,type,of,NP1,VP1,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,keeps,NP2,VP2,AA,AA,AA,AA,AA\\r\\nwhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nwhat,VP1,ADJP1,PP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nwhat,VP1,ADJP1,NP2,AA,AA,AA,AA,AA\\r\\nwhat,does,VP2,NP3,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWho,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP2,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,does,NP1,PP1,NP2,AA,AA,AA,AA\\r\\nwhat,NP2,PP1,NP3,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nwhat,NP2,PP1,NP3,AA,AA,AA,AA,AA\\r\\nwhat,NP1,PP1,VP2,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,PP1,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,kind,of,VP1,PP1,NP2,AA,AA,AA\\r\\nwhat,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nwhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,VP2,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,VP1,PP1,AA,AA,AA,AA,AA\\r\\nWhat,NP2,PP1,NP3,AA,AA,AA,AA,AA\\r\\nwhat,NP1,PP2,NP4,AA,AA,AA,AA,AA\\r\\nWhat,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nwhat,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,NP2,VP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,ADJP1,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nHow,many,types,of,VP1,NP2,AA,AA,AA\\r\\nwhat,keeps,NP2,VP2,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,PP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,does,PP1,NP4,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,PP1,NP3,VP2,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,PP1,AA,AA,AA,AA\\r\\nwhat,VP1,ADVP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,keeps,NP2,VP2,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP3,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhich,of,VP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,NP2,VP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,NP2,VP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP2,VP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nwhat,NP2,PP1,NP3,AA,AA,AA,AA,AA\\r\\nwhat,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP2,PP1,NP3,AA,AA,AA,AA,AA\\r\\nWhat,do,VP1,PP1,NP2,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,type,of,VP1,NP2,VP2,PP1,AA,AA\\r\\nwhat,NP2,PP1,NP3,AA,AA,AA,AA,AA\\r\\nwhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhere,do,NP1,VP1,NP2,PP1,AA,AA,AA\\r\\nwhat,do,NP1,VP1,NP2,PP1,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,type,of,VP1,NP1,AA,AA,AA,AA\\r\\nWhat,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,PP1,VP2,NP2,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,does,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,does,AA,AA,AA,AA,AA,AA,AA\\r\\nWhat,type,of,NP3,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,NP2,AA,AA,AA,AA,AA\\r\\nWhich,of,VP1,PP1,AA,AA,AA,AA,AA\\r\\nWhat,type,of,VP1,NP2,PP1,NP3,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,did,NP1,PP1,AA,AA,AA,AA,AA\\r\\nWhat,type,of,NP3,AA,AA,AA,AA,AA\\r\\nWhat,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP2,PP1,NP3,PP2,NP4,AA,AA,AA\\r\\nWhat,part,of,NP1,VP1,ADJP1,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,NP2,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nwhat,do,PP1,NP3,AA,AA,AA,AA,AA\\r\\nWhat,kind,of,NP1,VP1,AA,AA,AA,AA\\r\\nwhat,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,VP2,NP3,AA,AA,AA,AA\\r\\nWhat,type,of,VP1,NP2,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,PP1,AA,AA,AA,AA\\r\\nWhich,types,of,VP1,PP1,NP2,PP2,NP3,AA\\r\\nWhat,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,PP1,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,ADVP1,AA,AA,AA,AA\\r\\nWhat,kind,of,NP1,VP1,ADJP1,VP2,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,PP1,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,PP1,NP2,VP1,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,ADJP1,PP1,AA,AA,AA\\r\\nwhat,VP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhy,do,NP1,VP1,NP2,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,VP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nWhat,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,NP2,NP3,AA,AA,AA,AA,AA\\r\\nWhat,NP2,VP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,does,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,ADJP1,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,ADVP1,NP1,VP1,PP1,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhy,does,NP2,PP1,NP4,AA,AA,AA,AA\\r\\nwhat,PP1,VP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nwhat,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,type,of,NP1,VP1,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP2,VP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP2,AA,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,PP1,VP2,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nwhat,NP1,VP1,ADJP1,PP1,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,PP1,AA,AA,AA,AA\\r\\nWhat,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhere,do,NP1,VP1,NP2,PP1,AA,AA,AA\\r\\nwhat,do,PP1,NP2,AA,AA,AA,AA,AA\\r\\nwhat,do,VP1,PP1,NP2,AA,AA,AA,AA\\r\\nWhat,NP2,PP1,NP3,AA,AA,AA,AA,AA\\r\\nWhat,does,NP1,NP2,PP1,AA,AA,AA,AA\\r\\nWhat,does,NP1,NP2,PP1,AA,AA,AA,AA\\r\\nWhat,kind,of,PP1,NP4,AA,AA,AA,AA\\r\\nWhat,type,of,NP3,PP1,NP4,AA,AA,AA\\r\\nHow,do,NP1,VP1,NP2,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,ADJP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,does,PP1,NP3,VP2,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,do,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,NP2,PP1,AA,AA,AA\\r\\nwhat,does,NP1,PP1,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,PP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nwhat,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,NP2,VP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,type,of,VP1,PP1,NP2,AA,AA,AA\\r\\nWhat,PP1,NP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,PP1,VP2,AA,AA,AA,AA\\r\\nwhat,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,ADVP1,AA,AA,AA,AA,AA\\r\\nwhat,does,NP1,ADJP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,PP1,AA,AA,AA,AA\\r\\nWhat,NP1,PP1,VP1,ADJP1,AA,AA,AA,AA\\r\\nwhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,does,NP1,PP1,AA,AA,AA,AA,AA\\r\\nWhat,ADVP1,PP1,VP2,AA,AA,AA,AA,AA\\r\\nHow,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nwhat,kind,of,VP1,ADJP1,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nHow,many,ADVP1,NP1,VP1,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,ADJP1,PP1,AA,AA,AA,AA\\r\\nWhat,type,of,NP1,NP2,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,NP2,PP1,NP3,AA,AA,AA,AA,AA\\r\\nWhat,does,PP1,NP3,AA,AA,AA,AA,AA\\r\\nwhat,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,PP1,NP3,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,PP1,NP3,AA,AA,AA\\r\\nWhat,do,NP1,VP1,PP1,NP3,AA,AA,AA\\r\\nWhat,do,NP2,NP3,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,PP1,NP3,AA,AA,AA\\r\\nWhat,do,NP1,VP1,NP2,PP1,AA,AA,AA\\r\\nWhat,do,NP1,VP1,PP1,NP3,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,does,NP1,PP1,AA,AA,AA,AA,AA\\r\\nWhich,of,VP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,NP2,PP2,NP3,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhich,NP2,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,kind,of,NP1,VP1,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nWhat,kind,of,VP1,NP3,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,PP1,AA,AA,AA,AA,AA\\r\\nwhere,does,NP1,PP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nwhat,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nwhat,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nHow,do,NP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nHow,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,NP2,VP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhere,does,NP1,PP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,keeps,NP2,ADJP1,AA,AA,AA,AA,AA\\r\\nwhat,does,NP1,NP2,PP1,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,kind,of,PP1,NP3,AA,AA,AA,AA\\r\\nWhat,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhere,part,of,VP1,PP1,NP3,AA,AA,AA\\r\\nwhere,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP2,AA,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,NP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhich,of,VP1,NP2,AA,AA,AA,AA,AA\\r\\nwhat,type,of,NP2,NP3,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,does,PP1,NP3,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nWhy,do,NP1,NP3,AA,AA,AA,AA,AA\\r\\nWhat,NP2,VP2,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nwhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nwhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,PP1,NP3,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,PP1,NP3,VP2,NP4,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,do,VP1,PP1,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,kind,of,PP1,NP2,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nWhat,does,NP1,PP1,NP3,AA,AA,AA,AA\\r\\nWhat,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,does,NP1,NP2,PP1,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhich,of,VP1,NP2,PP1,NP3,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,VP2,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,ADJP1,PP1,NP3,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,NP2,PP1,NP3,AA,AA,AA,AA,AA\\r\\nWhat,NP2,PP1,NP3,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,type,of,NP1,VP1,AA,AA,AA,AA\\r\\nwhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nwhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,VP2,AA,AA,AA,AA,AA\\r\\nWhat,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nwhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,VP1,PP1,AA,AA,AA,AA,AA\\r\\nwhat,PP1,NP2,VP1,AA,AA,AA,AA,AA\\r\\nWhat,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nwhat,does,NP1,VP2,AA,AA,AA,AA,AA\\r\\nwhat,VP1,PP1,VP2,AA,AA,AA,AA,AA\\r\\nWhat,type,of,VP1,NP2,NP3,ADVP1,AA,AA\\r\\nWhere,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nwhat,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP2,PP1,NP3,AA,AA,AA,AA,AA\\r\\nwhat,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nWhich,type,of,PP1,NP3,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nwhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,kind,of,NP1,VP1,AA,AA,AA,AA\\r\\nWhat,type,of,NP1,VP1,AA,AA,AA,AA\\r\\nWhat,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nwhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,PP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,PP1,VP2,AA,AA,AA,AA\\r\\nwhere,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,does,NP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,NP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nwhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,does,NP1,VP1,NP2,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,kind,of,VP1,NP2,ADJP1,PP1,AA,AA\\r\\nwhat,kind,of,VP1,ADJP1,PP1,NP2,AA,AA\\r\\nWhat,kind,of,VP1,NP2,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,does,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwhat,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhat,kind,of,NP1,NP2,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,NP2,VP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP2,NP2,AA,AA,AA,AA,AA\\r\\nWhat,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhen,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwho,VP1,NP2,ADVP1,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,PP1,NP3,ADVP1,AA,AA,AA\\r\\nWhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nwhat,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nWhere,do,NP1,VP1,NP2,AA,AA,AA,AA\\r\\nwhat,NP1,PP1,VP2,AA,AA,AA,AA,AA\\r\\nwhat,NP1,PP1,VP2,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nwhat,NP1,VP1,PP1,AA,AA,AA,AA,AA\\r\\nwhat,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nwhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nwhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWho,VP1,NP2,PP1,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhen,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,NP1,PP1,NP2,VP1,AA,AA,AA,AA\\r\\nHow,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWho,does,NP1,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP1,ADJP1,PP1,ADJP2,AA,AA,AA,AA\\r\\nWhy,VP1,AA,AA,AA,AA,AA,AA,AA\\r\\nHow,did,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhat,did,NP1,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nwho,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWho,NP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhy,did,NP1,NP2,AA,AA,AA,AA,AA\\r\\nHow,did,NP1,NP2,AA,AA,AA,AA,AA\\r\\nWhich,NP3,AA,AA,AA,AA,AA,AA,AA\\r\\nWhen,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWhen,did,NP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhere,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWho,did,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhose,VP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhose,VP1,AA,AA,AA,AA,AA,AA,AA\\r\\nwhen,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhen,do,VP1,NP1,VP2,NP2,AA,AA,AA\\r\\nwhen,does,AA,AA,AA,AA,AA,AA,AA\\r\\nWhen,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhen,NP2,AA,AA,AA,AA,AA,AA,AA\\r\\nWhen,VP2,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nwhere,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,NP2,AA,AA,AA,AA,AA,AA,AA\\r\\nwhere,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nwhere,VP1,VP2,AA,AA,AA,AA,AA,AA\\r\\nwhere,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nwhere,NP1,PP1,NP2,PP2,AA,AA,AA,AA\\r\\nwhere,NP1,PP1,NP2,PP2,AA,AA,AA,AA\\r\\nWhere,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhere,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhere,do,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,do,NP3,AA,AA,AA,AA,AA,AA\\r\\nWhere,do,NP1,VP1,NP2,AA,AA,AA,AA\\r\\nWhere,do,AA,AA,AA,AA,AA,AA,AA\\r\\nwhere,do,NP1,ADJP1,AA,AA,AA,AA,AA\\r\\nWhere,do,AA,AA,AA,AA,AA,AA,AA\\r\\nwhere,do,NP1,PP1,NP2,VP1,AA,AA,AA\\r\\nwhere,do,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhere,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhere,do,NP1,PP1,AA,AA,AA,AA,AA\\r\\nWhere,do,NP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,do,NP1,VP1,NP2,PP1,AA,AA,AA\\r\\nWhere,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhere,do,NP1,NP2,AA,AA,AA,AA,AA\\r\\nWhere,do,VP1,NP2,AA,AA,AA,AA,AA\\r\\nWhere,do,NP1,VP1,NP2,AA,AA,AA,AA\\r\\nwhere,do,NP1,PP1,NP2,AA,AA,AA,AA\\r\\nWhere,do,NP1,VP1,NP2,PP1,AA,AA,AA\\r\\nWhere,do,NP1,VP1,NP2,AA,AA,AA,AA\\r\\nWhere,do,NP1,VP1,NP2,AA,AA,AA,AA\\r\\nWhere,do,NP1,VP1,NP2,AA,AA,AA,AA\\r\\nwhere,do,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,does,NP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,does,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhere,does,NP3,AA,AA,AA,AA,AA,AA\\r\\nWhere,does,AA,AA,AA,AA,AA,AA,AA\\r\\nwhere,does,NP1,PP1,AA,AA,AA,AA,AA\\r\\nwhere,does,NP1,PP1,AA,AA,AA,AA,AA\\r\\nWhere,does,NP1,NP2,AA,AA,AA,AA,AA\\r\\nWhere,does,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,does,PP2,AA,AA,AA,AA,AA,AA\\r\\nWhere,NP2,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,NP1,PP1,NP2,AA,AA,AA,AA\\r\\nwhere,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nwhere,NP1,PP2,PP3,NP3,AA,AA,AA,AA\\r\\nWhere,part,of,VP1,PP1,PP2,NP3,AA,AA\\r\\nWhere,NP2,VP1,AA,AA,AA,AA,AA,AA\\r\\nwhere,NP1,VP1,NP2,VP2,AA,AA,AA,AA\\r\\nWhere,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP1,NP1,VP2,NP2,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,NP2,NP3,ADJP1,AA,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nwhich,NP1,ADJP1,PP1,ADJP2,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP1,NP2,VP2,NP3,AA,AA,AA,AA\\r\\nWhich,NP2,VP1,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP1,NP2,NP3,PP1,NP4,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,NP2,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,NP3,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP1,ADVP1,NP2,AA,AA,AA,AA,AA\\r\\nWhich,PP2,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,PP1,AA,AA,AA,AA,AA,AA,AA\\r\\nwhich,kind,of,AA,AA,AA,AA,AA,AA\\r\\nWhich,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhich,PP1,NP3,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,NP3,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,of,VP1,NP2,AA,AA,AA,AA,AA\\r\\nWhich,of,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nwhich,of,VP1,NP2,PP1,NP3,AA,AA,AA\\r\\nWhich,of,VP1,NP2,AA,AA,AA,AA,AA\\r\\nWhich,of,VP1,NP2,AA,AA,AA,AA,AA\\r\\nWhich,of,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,of,NP1,AA,AA,AA,AA,AA,AA\\r\\nWhich,of,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,of,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhich,of,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,of,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,of,VP1,PP1,AA,AA,AA,AA,AA\\r\\nWhich,of,PP2,AA,AA,AA,AA,AA,AA\\r\\nWhich,of,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,of,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhich,of,VP2,PP1,NP3,AA,AA,AA,AA\\r\\nWhich,of,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,of,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,NP2,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP1,ADVP1,NP2,NP3,AA,AA,AA,AA\\r\\nWhich,PP1,NP2,PP2,NP3,AA,AA,AA,AA\\r\\nWhich,NP4,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,NP1,NP3,AA,AA,AA,AA,AA,AA\\r\\nWhich,ADVP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,NP1,NP4,AA,AA,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nwhich,VP1,PP2,AA,AA,AA,AA,AA,AA\\r\\nWhich,NP2,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,type,of,NP2,AA,AA,AA,AA,AA\\r\\nWhich,type,of,PP1,NP3,AA,AA,AA,AA\\r\\nWhich,type,of,AA,AA,AA,AA,AA,AA\\r\\nWhich,type,of,VP1,PP1,NP2,PP2,NP3,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,VP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nwho,VP1,NP2,ADVP1,AA,AA,AA,AA,AA\\r\\nWho,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWho,VP1,NP2,VP2,PP1,NP3,AA,AA,AA\\r\\nWho,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,NP2,PP1,NP3,AA,AA,AA,AA,AA\\r\\nWho,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhy,do,NP1,AA,AA,AA,AA,AA,AA\\r\\nwhy,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhy,do,NP1,VP1,NP2,AA,AA,AA,AA\\r\\nWhy,do,NP1,NP3,AA,AA,AA,AA,AA\\r\\nWhy,does,NP2,PP1,NP4,AA,AA,AA,AA\\r\\nWhy,does,PP1,NP2,AA,AA,AA,AA,AA\\r\\nwhere,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nwho,VP1,AA,AA,AA,AA,AA,AA,AA\\r\\nwho,NP1,PP2,NP2,AA,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nwho,VP1,NP3,PP1,NP4,AA,AA,AA,AA\\r\\nWho,NP2,PP1,NP3,AA,AA,AA,AA,AA\\r\\nWho,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nWho,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nWho,NP2,PP1,NP3,AA,AA,AA,AA,AA\\r\\nWho,VP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWho,VP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nWho,VP1,NP2,VP2,NP3,PP1,NP4,AA,AA\\r\\nWho,VP1,ADJP1,VP2,NP2,PP1,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,PP1,NP3,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP1,VP2,NP3,AA,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,PP1,NP3,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP1,PP1,NP3,AA,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhich,NP2,PP2,AA,AA,AA,AA,AA,AA\\r\\nwhere,VP1,VP2,AA,AA,AA,AA,AA,AA\\r\\nWhich,NP3,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP2,NP3,AA,AA,AA,AA,AA,AA\\r\\nwhich,PP1,PP2,NP4,AA,AA,AA,AA,AA\\r\\nWhich,VP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nwho,VP1,AA,AA,AA,AA,AA,AA,AA\\r\\nHow,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nWho,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nWhat,does,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWho,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWho,VP1,NP2,PP1,NP3,PP2,NP4,AA,AA\\r\\nWho,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nWho,PP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWho,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nWho,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nWho,VP1,NP2,PP1,VP2,NP3,AA,AA,AA\\r\\nWho,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhere,does,VP1,PP1,AA,AA,AA,AA,AA\\r\\nWhere,do,NP1,VP1,NP2,AA,AA,AA,AA\\r\\nWhere,do,NP1,VP1,NP2,AA,AA,AA,AA\\r\\nWhere,do,NP1,VP1,AA,AA,AA,AA,AA\\r\\nWhere,do,NP1,VP1,NP2,AA,AA,AA,AA\\r\\nWhere,do,NP1,VP1,NP2,AA,AA,AA,AA\\r\\nWhere,do,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,does,VP1,NP2,AA,AA,AA,AA,AA\\r\\nWhere,do,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,do,NP1,VP1,NP2,AA,AA,AA,AA\\r\\nWho,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nHow,many,VP1,PP1,NP2,AA,AA,AA,AA\\r\\nHow,many,PP2,AA,AA,AA,AA,AA,AA\\r\\nwhich,ADJP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhich,VP1,PP1,NP2,AA,AA,AA,AA,AA\\r\\nWhat,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nWhich,VP1,ADJP1,NP2,PP1,NP3,AA,AA,AA\\r\\nWhich,VP1,ADJP1,PP1,NP2,AA,AA,AA,AA\\r\\nAA,PP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,NP2,PP1,NP3,AA,AA,AA,AA,AA\\r\\nWhere,VP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWhat,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nwhere,NP1,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nWhich,NP1,PP1,VP1,AA,AA,AA,AA,AA\\r\\nWhere,PP1,AA,AA,AA,AA,AA,AA,AA\\r\\nwhere,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,NP1,PP2,AA,AA,AA,AA,AA,AA\\r\\nwhere,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nDoes,NP2,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,NP1,VP1,AA,AA,AA,AA,AA,AA\\r\\nHow,ADJP1,AA,AA,AA,AA,AA,AA,AA\\r\\nDoes,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,NP2,PP2,AA,AA,AA,AA,AA\\r\\nWhere,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhich,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWhich,NP2,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,VP2,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nHow,much,does,PP3,NP4,AA,AA,AA,AA\\r\\nHow,Much,does,NP2,PP2,NP3,AA,AA,AA\\r\\nHow,much,AA,AA,AA,AA,AA,AA,AA\\r\\nHow,much,does,NP2,PP3,NP4,AA,AA,AA\\r\\nWho,PP2,NP3,AA,AA,AA,AA,AA,AA\\r\\nWho,VP2,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,VP1,NP2,PP1,AA,AA,AA,AA,AA\\r\\nWho,NP2,PP1,AA,AA,AA,AA,AA,AA\\r\\nWhy,NP1,VP1,NP2,PP1,AA,AA,AA,AA\\r\\nWhich,VP1,NP2,PP1,NP3,AA,AA,AA,AA\\r\\nWho,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,PP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,NP2,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,PP1,NP3,AA,AA,AA,AA,AA,AA\\r\\nWho,NP2,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,AA,AA,AA,AA,AA,AA,AA\\r\\nHow,much,did,AA,AA,AA,AA,AA,AA\\r\\nWho,VP1,PP2,NP4,PP3,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhich,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,VP1,AA,AA,AA,AA,AA,AA,AA\\r\\nwho,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,AA,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,NP3,PP1,NP4,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADJP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,ADVP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,ADVP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,ADVP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,ADVP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWhere,VP1,ADVP1,AA,AA,AA,AA,AA,AA\\r\\nWho,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWho,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWho,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWho,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWho,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWho,VP1,NP2,AA,AA,AA,AA,AA,AA\\r\\nWho,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\nWho,NP1,AA,AA,AA,AA,AA,AA,AA\\r\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73wmoZi0E_Uy"
      },
      "source": [
        "Qt=[]\n",
        "with open(r'1000 QuesPhrase.csv', encoding='latin1') as csvfile:  # This dataset have only list of sentences and it will close the file automatically.\n",
        "    reader = csv.reader(csvfile)\n",
        "    for t in reader: \n",
        "       Qt.append(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMZW2RX-E4YT",
        "outputId": "06d9a5d4-ba90-485f-9a57-9b8be9fc5ea4"
      },
      "source": [
        "Q=[]\n",
        "for ques in zip(Qt):\n",
        "  #x=re.sub(\"[^-9A-Za-z ]\", \"\" , str(sent))\n",
        "  x=re.sub(\"[']\", \"\" , str(ques))\n",
        "  x=re.sub(\"[,]\", \"\" , str(x))\n",
        "  x=re.sub(\"[[]\", \"\" , str(x))\n",
        "  x=re.sub(\"[]]\", \"\" , str(x))\n",
        "  x=re.sub(\"[)]\", \"\" , str(x))\n",
        "  x=re.sub(\"[(]\", \"\" , str(x))\n",
        "  Q.append(x)\n",
        "print(Q[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What type of PP2 NP3 AA AA AA AA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gchvMm3Hsc_k"
      },
      "source": [
        "**One Hot Encoding for Question**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeX75pJnfXb8"
      },
      "source": [
        "QVec=[]\n",
        "for ques in zip(Q):\n",
        "    token=word_tokenize(str(ques[0]))\n",
        "    vectorizer = CountVectorizer(min_df=0, lowercase=False)\n",
        "    vectorizer.fit(NewPOS_Voc)\n",
        "    vectorizer.vocabulary_\n",
        "    vectorizer.fit_transform(NewPOS_Voc)\n",
        "    X=vectorizer.transform(token).toarray()\n",
        "    #######################################################\n",
        "    v_length=360 #sentence having 9 phrases\n",
        "    X = X.reshape(1,v_length)\n",
        "    for i in X: \n",
        "      QVec.append(X)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nalczCo5fjJc"
      },
      "source": [
        "**End of Importing and Encoding of Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BPvIf_BHmVP"
      },
      "source": [
        "## **2 Build MLP Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JseFu8NZ8v4X"
      },
      "source": [
        "SVec=np.array(SVec)\n",
        "QVec=np.array(QVec)\n",
        "X_train ,X_test = train_test_split(SVec,test_size=0.1)\n",
        "y_train ,y_test = train_test_split(QVec,test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAWxOJP1NlP-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "6a2e4939-d727-4a77-e5a2-bc6a58252d8e"
      },
      "source": [
        "'''\n",
        "SVec=np.array(SVec)\n",
        "QVec=np.array(QVec)\n",
        "\n",
        "\n",
        "X_train = SVec[:2000,0:360]#SVec[:600,0:360]\n",
        "y_train = QVec[:2000,0:360]#QVec[:600,0:360]\n",
        "\n",
        "X_train = SVec[:600,0:360]\n",
        "y_train = QVec[:600,0:360]\n",
        "\n",
        "X_test = SVec[600:637,0:360]\n",
        "y_test = QVec[600:637,0:360]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-f66eed63920e>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    y_test = QVec[600:637,0:360]\u001b[0m\n\u001b[0m                                \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS1AIE8yxHe7"
      },
      "source": [
        "**Build Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKiMI0-jyJ2M"
      },
      "source": [
        "**Create, compile, fit and evaluate model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LkTc4POw34n"
      },
      "source": [
        "import numpy\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Dense\n",
        "from sklearn.metrics import accuracy_score\n",
        "# create model\n",
        "model = Sequential()\n",
        "'''\n",
        "model.add(Dense(5000, input_shape=(2125,1,360), activation='relu'))\n",
        "model.add(Dense(3000, activation='relu'))\n",
        "model.add(Dense(360, activation='sigmoid'))\n",
        "\n",
        "'''\n",
        "model.add(Dense(3000, input_shape=(1000,1,360), activation='relu')) #637#667#1000\n",
        "model.add(Dense(2000, activation='relu'))\n",
        "model.add(Dense(360, activation='sigmoid'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxlYahhz--SV",
        "outputId": "281c77f1-408c-44e3-b507-0059114537e0"
      },
      "source": [
        "# Fit the model\n",
        "model.fit(X_train,y_train, epochs=100, batch_size=360, verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 1000, 1, 360) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1000, 1, 360), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 1, 360).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 1000, 1, 360) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1000, 1, 360), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 1, 360).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f467b6bc7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y90l8HsezB9E",
        "outputId": "1be3c002-fdbf-4462-88fb-83cf5d7349cf"
      },
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 1000, 1, 360) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1000, 1, 360), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 1, 360).\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0097 - accuracy: 0.0000e+00\n",
            "accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1d_2wMk28Wa"
      },
      "source": [
        "## **3 Read new sentence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5tzGK9BdY9S",
        "outputId": "dffd0ac8-5006-43db-f24b-7bbe428185d2"
      },
      "source": [
        "#1\n",
        "sentence = input(\"Enter your sentence: \")\n",
        "print(sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your sentence: GERD is located in Ethiopia.\n",
            "GERD is located in Ethiopia.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDVpdyav5rEP"
      },
      "source": [
        "## **4 Install pattern**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV28luKuDU_i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12870faa-fb21-47dc-fbb5-53a535e5c4ab"
      },
      "source": [
        "pip install Pattern"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Pattern\n",
            "  Downloading Pattern-3.6.0.tar.gz (22.2 MB)\n",
            "\u001b[K     || 22.2 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from Pattern) (0.16.0)\n",
            "Collecting backports.csv\n",
            "  Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n",
            "Collecting mysqlclient\n",
            "  Downloading mysqlclient-2.0.3.tar.gz (88 kB)\n",
            "\u001b[K     || 88 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from Pattern) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from Pattern) (4.2.6)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n",
            "\u001b[K     || 81 kB 227 kB/s \n",
            "\u001b[?25hCollecting pdfminer.six\n",
            "  Downloading pdfminer.six-20201018-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     || 5.6 MB 39.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from Pattern) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from Pattern) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from Pattern) (3.2.5)\n",
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[K     || 5.6 MB 12.6 MB/s \n",
            "\u001b[?25hCollecting cherrypy\n",
            "  Downloading CherryPy-18.6.1-py2.py3-none-any.whl (419 kB)\n",
            "\u001b[K     || 419 kB 61.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from Pattern) (2.23.0)\n",
            "Collecting cheroot>=8.2.1\n",
            "  Downloading cheroot-8.5.2-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[K     || 97 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from cherrypy->Pattern) (8.10.0)\n",
            "Collecting zc.lockfile\n",
            "  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting portend>=2.1.1\n",
            "  Downloading portend-2.7.1-py3-none-any.whl (5.3 kB)\n",
            "Collecting jaraco.collections\n",
            "  Downloading jaraco.collections-3.4.0-py3-none-any.whl (10 kB)\n",
            "Collecting jaraco.functools\n",
            "  Downloading jaraco.functools-3.3.0-py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from cheroot>=8.2.1->cherrypy->Pattern) (1.15.0)\n",
            "Collecting tempora>=1.8\n",
            "  Downloading tempora-4.1.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->Pattern) (2018.9)\n",
            "Collecting sgmllib3k\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "Collecting jaraco.classes\n",
            "  Downloading jaraco.classes-3.2.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting jaraco.text\n",
            "  Downloading jaraco.text-3.5.1-py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six->Pattern) (2.4.0)\n",
            "Collecting cryptography\n",
            "  Downloading cryptography-3.4.8-cp36-abi3-manylinux_2_24_x86_64.whl (3.0 MB)\n",
            "\u001b[K     || 3.0 MB 63.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from pdfminer.six->Pattern) (3.0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six->Pattern) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six->Pattern) (2.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->Pattern) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->Pattern) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->Pattern) (2.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zc.lockfile->cherrypy->Pattern) (57.4.0)\n",
            "Building wheels for collected packages: Pattern, mysqlclient, python-docx, sgmllib3k\n",
            "  Building wheel for Pattern (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Pattern: filename=Pattern-3.6-py3-none-any.whl size=22332721 sha256=a67e4d2d1e3f6d28b9c0aa958d08e27372412b1448a5cb5ce628f2469859d4d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/1f/4e/9b67afd2430d55dee90bd57618dd7d899f1323e5852c465682\n",
            "  Building wheel for mysqlclient (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mysqlclient: filename=mysqlclient-2.0.3-cp37-cp37m-linux_x86_64.whl size=100142 sha256=d4157b708811f48ea32d2edb8d9aacaa6cb53a770557b22f0f68633b8a665a3d\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/1c/f8/11fafab45fe6696eea63794a5d747b9c6b54990ac6f1885fb7\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184508 sha256=3751169a633ce268331caf9c65374a3a15602669ad4c821caf3431b68bcf7d6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6065 sha256=c918fca055b313766a7a3bf5fd1b4b1e6c121d7e758b2d0bf137333df61d4200\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n",
            "Successfully built Pattern mysqlclient python-docx sgmllib3k\n",
            "Installing collected packages: jaraco.functools, tempora, jaraco.text, jaraco.classes, zc.lockfile, sgmllib3k, portend, jaraco.collections, cryptography, cheroot, python-docx, pdfminer.six, mysqlclient, feedparser, cherrypy, backports.csv, Pattern\n",
            "Successfully installed Pattern-3.6 backports.csv-1.0.7 cheroot-8.5.2 cherrypy-18.6.1 cryptography-3.4.8 feedparser-6.0.8 jaraco.classes-3.2.1 jaraco.collections-3.4.0 jaraco.functools-3.3.0 jaraco.text-3.5.1 mysqlclient-2.0.3 pdfminer.six-20201018 portend-2.7.1 python-docx-0.8.11 sgmllib3k-1.0.0 tempora-4.1.1 zc.lockfile-2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS_Ax4sGDuPI",
        "outputId": "7c5af765-723f-437b-8980-fe9f6f2792c4"
      },
      "source": [
        "pip install web.py==0.40-dev1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: web.py==0.40-dev1 in /usr/local/lib/python3.7/dist-packages (0.40.dev1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5DixfjrD1Ke"
      },
      "source": [
        "from pattern.en import parsetree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owSSHj7POEVn"
      },
      "source": [
        "## **5 Extract phrases from sentence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyOixTcfD1vu",
        "outputId": "fa847028-f9e4-465d-c828-2caa84bfc98d"
      },
      "source": [
        "#2 \n",
        "# Extract phrase from sentence\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#sentence=\"cnidarians are without backbones\"\n",
        "\n",
        "#Lowercase all characters\n",
        "sentence=sentence.lower()\n",
        "\n",
        "tree=parsetree(sentence)\n",
        "\n",
        "VP1=NP1=PP1=ADJP1=ADVP1=\"\"\n",
        "VP2=NP2=PP2=ADJP2=ADVP2=\"\"\n",
        "VP3=NP3=PP3=ADJP3=ADVP3=\"\"\n",
        "VP4=NP4=PP4=ADJP4=ADVP4=\"\"\n",
        "VP5=NP5=PP5=ADJP5=ADVP5=\"\"\n",
        "SenPhrase=[]\n",
        "SenColl=[]\n",
        "\n",
        "#.............................................\n",
        "for node in tree:\n",
        "  for chunk in node.chunks:\n",
        "    if ((chunk.type)=='NP'):\n",
        "        if (NP1==\"\"):\n",
        "          NP1=\"NP1\"\n",
        "          SenPhrase.append(NP1)\n",
        "          SenColl.append(chunk.string)\n",
        "        elif (NP1!=\"\" and NP2==\"\"):\n",
        "          NP2=\"NP2\"\n",
        "          SenPhrase.append(NP2)\n",
        "          SenColl.append(chunk.string)\n",
        "        elif (NP1!=\"\" and NP2!=\"\" and NP3==\"\"):\n",
        "          NP3=\"NP3\"\n",
        "          SenPhrase.append(NP3)\n",
        "          SenColl.append(chunk.string)\n",
        "        elif (NP1!=\"\" and NP2!=\"\" and NP3!=\"\" and NP4==\"\"):\n",
        "          NP4=\"NP4\"\n",
        "          SenPhrase.append(NP4)\n",
        "          SenColl.append(chunk.string)\n",
        "    elif ((chunk.type)=='VP'):\n",
        "        if (VP1==\"\"):\n",
        "          VP1=\"VP1\"\n",
        "          SenPhrase.append(VP1)\n",
        "          SenColl.append(chunk.string)\n",
        "        elif (VP1!=\"\" and VP2==\"\"):\n",
        "          VP2=\"VP2\"\n",
        "          SenPhrase.append(VP2)\n",
        "          SenColl.append(chunk.string)\n",
        "        elif (VP1!=\"\" and VP2!=\"\" and VP3==\"\"):\n",
        "          NP3=\"NP3\"\n",
        "          SenPhrase.append(VP3)\n",
        "          SenColl.append(chunk.string)\n",
        "        elif (VP1!=\"\" and VP2!=\"\" and VP3!=\"\" and VP4==\"\"):\n",
        "          NP4=\"NP4\"\n",
        "          SenPhrase.append(VP4)\n",
        "          SenColl.append(chunk.string)\n",
        "    elif ((chunk.type)=='PP'):\n",
        "        if (PP1==\"\"):\n",
        "          PP1=\"PP1\"\n",
        "          SenPhrase.append(PP1)\n",
        "          SenColl.append(chunk.string)\n",
        "        elif (PP1!=\"\" and PP2==\"\"):\n",
        "          PP2=\"PP2\"\n",
        "          SenPhrase.append(PP2)\n",
        "          SenColl.append(chunk.string)\n",
        "        elif (PP1!=\"\" and PP2!=\"\" and PP3==\"\"):\n",
        "          PP3=\"PP3\"\n",
        "          SenPhrase.append(PP3)\n",
        "          SenColl.append(chunk.string)\n",
        "        elif (PP1!=\"\" and PP2!=\"\" and PP3!=\"\" and PP4==\"\"):\n",
        "          PP4=\"PP4\"  \n",
        "          SenPhrase.append(PP4)\n",
        "          SenColl.append(chunk.string)\n",
        "    elif ((chunk.type)=='ADJP'):\n",
        "        if (ADJP1==\"\"):\n",
        "          ADJP1=\"ADJP1\"\n",
        "          SenPhrase.append(ADJP1)\n",
        "          SenColl.append(chunk.string)\n",
        "        elif (ADJP1!=\"\" and ADJP2==\"\"):\n",
        "          ADJP2=\"ADJP2\"\n",
        "          SenPhrase.append(ADJP2)\n",
        "          SenColl.append(chunk.string)\n",
        "        elif (ADJP1!=\"\" and ADJP2!=\"\" and ADJP3==\"\"):\n",
        "          ADJP3=\"ADJP3\"\n",
        "          SenPhrase.append(ADJP3)\n",
        "          SenColl.append(chunk.string)\n",
        "        elif (ADJP1!=\"\" and ADJP2!=\"\" and ADJP3!=\"\" and ADJP4==\"\"):\n",
        "          ADJP4=\"ADJP4\"  \n",
        "          SenPhrase.append(ADJP4)\n",
        "          SenColl.append(chunk.string)\n",
        "    elif ((chunk.type)=='ADVP'):\n",
        "        if (ADVP1==\"\"):\n",
        "          ADVP1=\"ADVP1\"\n",
        "          SenPhrase.append(ADVP1)\n",
        "          SenColl.append(chunk.string)\n",
        "        elif (ADVP1!=\"\" and ADVP2==\"\"):\n",
        "          ADVP2=\"ADVP2\"\n",
        "          SenPhrase.append(ADVP2)\n",
        "          SenColl.append(chunk.string)\n",
        "        elif (ADVP1!=\"\" and ADVP2!=\"\" and ADVP3==\"\"):\n",
        "          ADVP3=\"ADVP3\"\n",
        "          SenPhrase.append(ADVP3)\n",
        "          SenColl.append(chunk.string)\n",
        "        elif (ADJP1!=\"\" and ADVP2!=\"\" and ADVP3!=\"\" and ADVP4==\"\"):\n",
        "          ADVP4=\"ADVP4\" \n",
        "          SenPhrase.append(ADVP4) \n",
        "          SenColl.append(chunk.string)\n",
        "'''\n",
        "for x,y in enumerate(SenColl):\n",
        "  for z in QuesColl:\n",
        "    if (y==z):\n",
        "      QuesPhrase.append(SenPhrase[x])\n",
        "'''\n",
        "print(\"SenPhrase=\",SenPhrase)\n",
        "print(\"SenColl=\",SenColl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SenPhrase= ['NP1', 'VP1', 'PP1', 'NP2']\n",
            "SenColl= ['gerd', 'is located', 'in', 'ethiopia']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptvRQqWpJ9hZ"
      },
      "source": [
        "## **6 Vector Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W3Sev4Xdn4R",
        "outputId": "ea6ba1be-edd0-440b-bc73-6f100c3a4d75"
      },
      "source": [
        "#3 Data clean up\n",
        "Te=SenPhrase\n",
        "for x in range(9-len(Te)):\n",
        "  Te.append(\"AA\")\n",
        "Te = \" \".join(Te)\n",
        "print(Te)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NP1 VP1 PP1 NP2 AA AA AA AA AA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muCkfr0YdKXD"
      },
      "source": [
        "#4\n",
        "TVec=[]\n",
        "#for sent in zip(Te):\n",
        "to=word_tokenize(str(Te))\n",
        "vectorizer = CountVectorizer(min_df=0, lowercase=False)\n",
        "vectorizer.fit(NewPOS_Voc)\n",
        "vectorizer.vocabulary_\n",
        "vectorizer.fit_transform(NewPOS_Voc)\n",
        "d=vectorizer.transform(to).toarray()\n",
        "\n",
        "###############################################################\n",
        "\n",
        "v_length=360\n",
        "d = d.reshape(1,v_length)\n",
        "for i in d: \n",
        "  TVec.append(d)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo7Jj7V8gPoT"
      },
      "source": [
        "#5\n",
        "yresult = model.predict(TVec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a24UuxvNHuJM"
      },
      "source": [
        "## **7 Decode the Predicted vector into text form**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2Vk4vO1-SQx"
      },
      "source": [
        "**Split the predicted result in to 9(Default no of phrases)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4SxaiYIIRzh"
      },
      "source": [
        "Word_vector=[]\n",
        "yresult = yresult.reshape(v_length)\n",
        "a=0\n",
        "b=40\n",
        "str(a)\n",
        "str(b)\n",
        "\n",
        "for i in range(9):\n",
        "  Word_vector.append(yresult[a:b])\n",
        "  a=b\n",
        "  b=b+40"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVkNBvYqDNH3",
        "outputId": "4335a6e5-d053-4ac5-aee5-19a7f7e9bbc1"
      },
      "source": [
        "#6 Maximum index values\n",
        "index_max=[]\n",
        "phrasetag=[]\n",
        "for i in range(9):\n",
        "  values=np.array(Word_vector[i])\n",
        "  temp=[]\n",
        "  max = np.argmax(values)\n",
        "  index_max.append(max)\n",
        "  #.....................................\n",
        "  temp.append(max)\n",
        "  for (key, ph) in enumerate(NewPOS_Voc):\n",
        "    for x in temp:\n",
        "      if (key==x):\n",
        "        print(key,ph)\n",
        "\n",
        "        phrasetag.append(ph)\n",
        "#print(index_max)\n",
        "print(phrasetag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37 what\n",
            "21 VP1\n",
            "12 NP2\n",
            "0 AA\n",
            "0 AA\n",
            "0 AA\n",
            "0 AA\n",
            "0 AA\n",
            "0 AA\n",
            "['what', 'VP1', 'NP2', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KTGJKSFqc3B"
      },
      "source": [
        "**Fixing the treshlod for the predicted value or Identify top 5 values**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IASl9u74I6C-"
      },
      "source": [
        "## **8 Predicted Sentence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ob82AkaLk0o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5834b9f5-5b25-43d4-e633-b33cc4a9ad6a"
      },
      "source": [
        "predSent=[]\n",
        "#for (key,val) in enumerate(phrasetag):\n",
        "#print(val)\n",
        "predSent.append(phrasetag[0])\n",
        "for i,j in enumerate(SenPhrase):\n",
        "  for (key,val) in enumerate(phrasetag):\n",
        "    if ((val==j)):\n",
        "      predSent.append(SenColl[i])\n",
        "print(predSent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['what', 'is located', 'ethiopia']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHKHerA2b8BF"
      },
      "source": [
        "## **9 Evaluation Metrics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Imeg2v242fJS"
      },
      "source": [
        "***BLUE Score***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gttsy8G_89V",
        "outputId": "0e06e848-faa2-405c-dbe0-3d3453edb0aa"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "reference = ['Who won the battle of adwa?'.split()]\n",
        "candidate = 'What ethiopia defeated the battle?'.split()\n",
        "print('BLEU score -> {}'.format(sentence_bleu(reference, candidate )))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score -> 0.5475182535069453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATsg2TRGuSD6",
        "outputId": "afd96241-2c6b-417e-f1bd-e72041b3652d"
      },
      "source": [
        "# n-gram individual BLEU\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "reference = ['Who is the president of Hungary?'.split()]\n",
        "candidate = 'What is hungary?'.split()\n",
        "print('Individual 1-gram: %f' % sentence_bleu(reference, candidate, weights=(1, 0, 0, 0)))\n",
        "print('Individual 2-gram: %f' % sentence_bleu(reference, candidate, weights=(0, 1, 0, 0)))\n",
        "print('Individual 3-gram: %f' % sentence_bleu(reference, candidate, weights=(0, 0, 1, 0)))\n",
        "print('Individual 4-gram: %f' % sentence_bleu(reference, candidate, weights=(0, 0, 0, 1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Individual 1-gram: 0.122626\n",
            "Individual 2-gram: 0.367879\n",
            "Individual 3-gram: 0.367879\n",
            "Individual 4-gram: 0.367879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJEsC5AE2h1J"
      },
      "source": [
        "***GLEU Score***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Rt2mcE41vnx",
        "outputId": "b2caa027-5732-4219-db6d-a4e178a508b1"
      },
      "source": [
        "import nltk\n",
        "import nltk.translate.gleu_score as gleu\n",
        "\n",
        "import numpy\n",
        "import os\n",
        "\n",
        "try:\n",
        "  nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "  nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-gC9E9i2Djp"
      },
      "source": [
        "hyp = str('Who is the president of Hungary?').split()\n",
        "ref_a = str('What is hungary?').split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rtw-s7vy2GhI",
        "outputId": "384a8b0c-777e-4ec1-fb56-0b7c404efd57"
      },
      "source": [
        "score_ref_a = gleu.sentence_gleu([ref_a], hyp)\n",
        "print(\"Hyp and ref_a are the same: {}\".format(score_ref_a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyp and ref_a are the same: 0.05555555555555555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFbM78IsWXnE"
      },
      "source": [
        "**Rouge Score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEaiECZYXGIH",
        "outputId": "48b24350-4f8e-4309-e5da-4f5153b319e2"
      },
      "source": [
        "pip install rouge-metric"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge-metric\n",
            "  Downloading rouge_metric-1.0.1-py3-none-any.whl (151 kB)\n",
            "\u001b[?25l\r\u001b[K     |                             | 10 kB 21.8 MB/s eta 0:00:01\r\u001b[K     |                           | 20 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |                         | 30 kB 29.9 MB/s eta 0:00:01\r\u001b[K     |                       | 40 kB 23.8 MB/s eta 0:00:01\r\u001b[K     |                     | 51 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |                   | 61 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |                | 71 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |              | 81 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |            | 92 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |          | 102 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |        | 112 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |      | 122 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |    | 133 kB 7.6 MB/s eta 0:00:01\r\u001b[K     | | 143 kB 7.6 MB/s eta 0:00:01\r\u001b[K     || 151 kB 7.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: rouge-metric\n",
            "Successfully installed rouge-metric-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CTbA8H4DXeW",
        "outputId": "4e657652-d7ab-4fb7-87d3-f841ddd9c76a"
      },
      "source": [
        "pip install rouge"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEFvnLnyCyBj"
      },
      "source": [
        "from rouge import Rouge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIljhnXlP9qO"
      },
      "source": [
        "#For template based question generation evaluation\n",
        "model_out = [\"Who discovered America in 1492?\",\n",
        "             \"When did John arrive?\",\n",
        "             \"How did John run to school?\",\n",
        "             \"Which is the fastest human sense?\",\n",
        "             \"Where Corn is grown?\",\n",
        "             \"What is the fastest bird?\",\n",
        "             \"What is the fastest insects?\",\n",
        "             \"Which human bones are stronger that concrete?\",\n",
        "             \"What is John favorite candy?\",\n",
        "             \"Who is the president of Hungary?\",\n",
        "             \"Who won the battle of adwa?\"]\n",
        "\n",
        "reference = [\"What does Columbus do in 1492?\",\n",
        "             \"What does John do at noon?\",\n",
        "             \"What does John do to school?\",\n",
        "             \"What does Hearing do fastest?\",\n",
        "             \"When does grown every on every antarctica?\",\n",
        "             \"What does the bird is the?\",\n",
        "             \"Who are the fastest of the insects?\",\n",
        "             \"What does bones do than Human concrete?\",\n",
        "             \"What does candy do John favorite?\",\n",
        "             \"What does Orban do of the Hungary?\",\n",
        "             \"Who defeated Italy at battle Adwa?\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QElsbcwZi6r"
      },
      "source": [
        "#For MLP based question generation evaluation\n",
        "model_out = [\"Who discovered America in 1492?\",\n",
        "             \"When did John arrive?\",\n",
        "             \"How did John run to school?\",\n",
        "             \"Which is the fastest human sense?\",\n",
        "             \"Where Corn is grown?\",\n",
        "             \"What is the fastest bird?\",\n",
        "             \"What is the fastest insects?\",\n",
        "             \"Which human bones are stronger that concrete?\",\n",
        "             \"What is John favorite candy?\",\n",
        "             \"Who is the president of Hungary?\",\n",
        "             \"Who won the battle of adwa?\"]\n",
        "\n",
        "reference = [\"What columbus discovered?\",\n",
        "             \"What arrived noon?\",\n",
        "             \"What ran school?\",\n",
        "             \"What is the fastest human sense?\",\n",
        "             \"What is grown every continent?\",\n",
        "             \"What is the peregrine falcon?\",\n",
        "             \"What are the fastest insects?\",\n",
        "             \"What human thigh bones are?\",\n",
        "             \"What favorite candy is?\",\n",
        "             \"What is hungary?\",\n",
        "             \"What ethiopia defeated the battle?\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lfc_yPoNWWQc"
      },
      "source": [
        "rouge = Rouge()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8xidgsTFcxn",
        "outputId": "11db0303-3011-4bd2-a0e8-927aacd62ab4"
      },
      "source": [
        "rouge.get_scores(model_out, reference)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'rouge-1': {'f': 0.0, 'p': 0.0, 'r': 0.0},\n",
              "  'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0},\n",
              "  'rouge-l': {'f': 0.0, 'p': 0.0, 'r': 0.0}},\n",
              " {'rouge-1': {'f': 0.0, 'p': 0.0, 'r': 0.0},\n",
              "  'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0},\n",
              "  'rouge-l': {'f': 0.0, 'p': 0.0, 'r': 0.0}},\n",
              " {'rouge-1': {'f': 0.22222221777777784,\n",
              "   'p': 0.16666666666666666,\n",
              "   'r': 0.3333333333333333},\n",
              "  'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0},\n",
              "  'rouge-l': {'f': 0.22222221777777784,\n",
              "   'p': 0.16666666666666666,\n",
              "   'r': 0.3333333333333333}},\n",
              " {'rouge-1': {'f': 0.8333333283333335,\n",
              "   'p': 0.8333333333333334,\n",
              "   'r': 0.8333333333333334},\n",
              "  'rouge-2': {'f': 0.7999999950000002, 'p': 0.8, 'r': 0.8},\n",
              "  'rouge-l': {'f': 0.8333333283333335,\n",
              "   'p': 0.8333333333333334,\n",
              "   'r': 0.8333333333333334}},\n",
              " {'rouge-1': {'f': 0.22222221728395072, 'p': 0.25, 'r': 0.2},\n",
              "  'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0},\n",
              "  'rouge-l': {'f': 0.22222221728395072, 'p': 0.25, 'r': 0.2}},\n",
              " {'rouge-1': {'f': 0.5999999950000001, 'p': 0.6, 'r': 0.6},\n",
              "  'rouge-2': {'f': 0.4999999950000001, 'p': 0.5, 'r': 0.5},\n",
              "  'rouge-l': {'f': 0.5999999950000001, 'p': 0.6, 'r': 0.6}},\n",
              " {'rouge-1': {'f': 0.7999999950000002, 'p': 0.8, 'r': 0.8},\n",
              "  'rouge-2': {'f': 0.4999999950000001, 'p': 0.5, 'r': 0.5},\n",
              "  'rouge-l': {'f': 0.7999999950000002, 'p': 0.8, 'r': 0.8}},\n",
              " {'rouge-1': {'f': 0.33333332847222225, 'p': 0.2857142857142857, 'r': 0.4},\n",
              "  'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0},\n",
              "  'rouge-l': {'f': 0.33333332847222225, 'p': 0.2857142857142857, 'r': 0.4}},\n",
              " {'rouge-1': {'f': 0.4444444395061729, 'p': 0.4, 'r': 0.5},\n",
              "  'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0},\n",
              "  'rouge-l': {'f': 0.4444444395061729, 'p': 0.4, 'r': 0.5}},\n",
              " {'rouge-1': {'f': 0.22222221777777784,\n",
              "   'p': 0.16666666666666666,\n",
              "   'r': 0.3333333333333333},\n",
              "  'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0},\n",
              "  'rouge-l': {'f': 0.22222221777777784,\n",
              "   'p': 0.16666666666666666,\n",
              "   'r': 0.3333333333333333}},\n",
              " {'rouge-1': {'f': 0.18181817685950424, 'p': 0.16666666666666666, 'r': 0.2},\n",
              "  'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0},\n",
              "  'rouge-l': {'f': 0.18181817685950424, 'p': 0.16666666666666666, 'r': 0.2}}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdwjBuQl2yTJ"
      },
      "source": [
        "***METEOR Score***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98g3Rq3dznbV"
      },
      "source": [
        "from nltk.translate\n",
        "print (nltk.translate.meteor_score.meteor_score(\n",
        "    [\"this is an apple\", \"that is an apple\"], \"an apple on this tree\"))\n",
        "print (nltk.translate.meteor_score.meteor_score(\n",
        "    [\"this is an apple\", \"that is an apple\"], \"a red color fruit\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy8jimsVOzPp"
      },
      "source": [
        "from datasets import load_metric\n",
        "metric = load_metric(\"meteor\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRPfaqC9aXpK"
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import wordnet\n",
        "from itertools import chain, product\n",
        "hypotheses = [\n",
        "    ['how are you'.split(), 'i am fine'.split()],                       # document 1: hypothesis\n",
        "    ['it is fine today'.split(), 'we won the football game'.split()],   # document 2: hypothesis\n",
        "]\n",
        "references = [[\n",
        "    ['how do you do'.split(), 'fine thanks'.split()],   # document 1: reference 1\n",
        "    ['how old are you'.split(), 'i am three'.split()],  # document 1: reference 2\n",
        "], [\n",
        "    ['it is sunny today'.split(), 'let us go for a walk'.split()],  # document 2: reference 1\n",
        "    ['it is a terrible day'.split(), 'we lost the game'.split()],   # document 2: reference 2\n",
        "]]\n",
        "\n",
        "def _generate_enums(hypothesis, reference, preprocess=str.lower):\n",
        "\n",
        "    hypothesis_list = list(enumerate(preprocess(hypothesis).split()))\n",
        "    reference_list = list(enumerate(preprocess(reference).split()))\n",
        "    return hypothesis_list, reference_list\n",
        "\n",
        "def exact_match(hypothesis, reference):\n",
        "\n",
        "    hypothesis_list, reference_list = _generate_enums(hypothesis, reference)\n",
        "    return _match_enums(hypothesis_list, reference_list)\n",
        "\n",
        "def _match_enums(enum_hypothesis_list, enum_reference_list):\n",
        "\n",
        "    word_match = []\n",
        "    for i in range(len(enum_hypothesis_list))[::-1]:\n",
        "        for j in range(len(enum_reference_list))[::-1]:\n",
        "            if enum_hypothesis_list[i][1] == enum_reference_list[j][1]:\n",
        "                word_match.append(\n",
        "                    (enum_hypothesis_list[i][0], enum_reference_list[j][0])\n",
        "                )\n",
        "                (enum_hypothesis_list.pop(i)[1], enum_reference_list.pop(j)[1])\n",
        "                break\n",
        "    return word_match, enum_hypothesis_list, enum_reference_list\n",
        "\n",
        "\n",
        "def _enum_stem_match(\n",
        "    enum_hypothesis_list, enum_reference_list, stemmer=PorterStemmer()\n",
        "):\n",
        "\n",
        "    stemmed_enum_list1 = [\n",
        "        (word_pair[0], stemmer.stem(word_pair[1])) for word_pair in enum_hypothesis_list\n",
        "    ]\n",
        "\n",
        "    stemmed_enum_list2 = [\n",
        "        (word_pair[0], stemmer.stem(word_pair[1])) for word_pair in enum_reference_list\n",
        "    ]\n",
        "\n",
        "    word_match, enum_unmat_hypo_list, enum_unmat_ref_list = _match_enums(\n",
        "        stemmed_enum_list1, stemmed_enum_list2\n",
        "    )\n",
        "\n",
        "    enum_unmat_hypo_list = (\n",
        "        list(zip(*enum_unmat_hypo_list)) if len(enum_unmat_hypo_list) > 0 else []\n",
        "    )\n",
        "\n",
        "    enum_unmat_ref_list = (\n",
        "        list(zip(*enum_unmat_ref_list)) if len(enum_unmat_ref_list) > 0 else []\n",
        "    )\n",
        "\n",
        "    enum_hypothesis_list = list(\n",
        "        filter(lambda x: x[0] not in enum_unmat_hypo_list, enum_hypothesis_list)\n",
        "    )\n",
        "\n",
        "    enum_reference_list = list(\n",
        "        filter(lambda x: x[0] not in enum_unmat_ref_list, enum_reference_list)\n",
        "    )\n",
        "\n",
        "    return word_match, enum_hypothesis_list, enum_reference_list\n",
        "\n",
        "def stem_match(hypothesis, reference, stemmer=PorterStemmer()):\n",
        "\n",
        "    enum_hypothesis_list, enum_reference_list = _generate_enums(hypothesis, reference)\n",
        "    return _enum_stem_match(enum_hypothesis_list, enum_reference_list, stemmer=stemmer)\n",
        "\n",
        "def _enum_wordnetsyn_match(enum_hypothesis_list, enum_reference_list, wordnet=wordnet):\n",
        "\n",
        "    word_match = []\n",
        "    for i in range(len(enum_hypothesis_list))[::-1]:\n",
        "        hypothesis_syns = set(\n",
        "            chain.from_iterable(\n",
        "                (\n",
        "                    lemma.name()\n",
        "                    for lemma in synset.lemmas()\n",
        "                    if lemma.name().find(\"_\") < 0\n",
        "                )\n",
        "                for synset in wordnet.synsets(enum_hypothesis_list[i][1])\n",
        "            )\n",
        "        ).union({enum_hypothesis_list[i][1]})\n",
        "        for j in range(len(enum_reference_list))[::-1]:\n",
        "            if enum_reference_list[j][1] in hypothesis_syns:\n",
        "                word_match.append(\n",
        "                    (enum_hypothesis_list[i][0], enum_reference_list[j][0])\n",
        "                )\n",
        "                enum_hypothesis_list.pop(i), enum_reference_list.pop(j)\n",
        "                break\n",
        "    return word_match, enum_hypothesis_list, enum_reference_list\n",
        "\n",
        "def wordnetsyn_match(hypothesis, reference, wordnet=wordnet):\n",
        "\n",
        "    enum_hypothesis_list, enum_reference_list = _generate_enums(hypothesis, reference)\n",
        "    return _enum_wordnetsyn_match(\n",
        "        enum_hypothesis_list, enum_reference_list, wordnet=wordnet\n",
        "    )\n",
        "\n",
        "def _enum_allign_words(\n",
        "    enum_hypothesis_list, enum_reference_list, stemmer=PorterStemmer(), wordnet=wordnet\n",
        "):\n",
        "\n",
        "    exact_matches, enum_hypothesis_list, enum_reference_list = _match_enums(\n",
        "        enum_hypothesis_list, enum_reference_list\n",
        "    )\n",
        "\n",
        "    stem_matches, enum_hypothesis_list, enum_reference_list = _enum_stem_match(\n",
        "        enum_hypothesis_list, enum_reference_list, stemmer=stemmer\n",
        "    )\n",
        "\n",
        "    wns_matches, enum_hypothesis_list, enum_reference_list = _enum_wordnetsyn_match(\n",
        "        enum_hypothesis_list, enum_reference_list, wordnet=wordnet\n",
        "    )\n",
        "\n",
        "    return (\n",
        "        sorted(\n",
        "            exact_matches + stem_matches + wns_matches, key=lambda wordpair: wordpair[0]\n",
        "        ),\n",
        "        enum_hypothesis_list,\n",
        "        enum_reference_list,\n",
        "    )\n",
        "\n",
        "def allign_words(hypothesis, reference, stemmer=PorterStemmer(), wordnet=wordnet):\n",
        "\n",
        "    enum_hypothesis_list, enum_reference_list = _generate_enums(hypothesis, reference)\n",
        "    return _enum_allign_words(\n",
        "        enum_hypothesis_list, enum_reference_list, stemmer=stemmer, wordnet=wordnet\n",
        "    )\n",
        "\n",
        "def _count_chunks(matches):\n",
        "\n",
        "    i = 0\n",
        "    chunks = 1\n",
        "    while i < len(matches) - 1:\n",
        "        if (matches[i + 1][0] == matches[i][0] + 1) and (\n",
        "            matches[i + 1][1] == matches[i][1] + 1\n",
        "        ):\n",
        "            i += 1\n",
        "            continue\n",
        "        i += 1\n",
        "        chunks += 1\n",
        "    return chunks\n",
        "\n",
        "def single_meteor_score(\n",
        "    reference,\n",
        "    hypothesis,\n",
        "    preprocess=str.lower,\n",
        "    stemmer=PorterStemmer(),\n",
        "    wordnet=wordnet,\n",
        "    alpha=0.9,\n",
        "    beta=3,\n",
        "    gamma=0.5,\n",
        "):\n",
        "\n",
        "    enum_hypothesis, enum_reference = _generate_enums(\n",
        "        hypothesis, reference, preprocess=preprocess\n",
        "    )\n",
        "    translation_length = len(enum_hypothesis)\n",
        "    reference_length = len(enum_reference)\n",
        "    matches, _, _ = _enum_allign_words(enum_hypothesis, enum_reference, stemmer=stemmer)\n",
        "    matches_count = len(matches)\n",
        "    try:\n",
        "        precision = float(matches_count) / translation_length\n",
        "        recall = float(matches_count) / reference_length\n",
        "        fmean = (precision * recall) / (alpha * precision + (1 - alpha) * recall)\n",
        "        chunk_count = float(_count_chunks(matches))\n",
        "        frag_frac = chunk_count / matches_count\n",
        "    except ZeroDivisionError:\n",
        "        return 0.0\n",
        "    penalty = gamma * frag_frac ** beta\n",
        "    return (1 - penalty) * fmean\n",
        "\n",
        "def meteor_score(\n",
        "    references,\n",
        "    hypothesis,\n",
        "    preprocess=str.lower,\n",
        "    stemmer=PorterStemmer(),\n",
        "    wordnet=wordnet,\n",
        "    alpha=0.9,\n",
        "    beta=3,\n",
        "    gamma=0.5,\n",
        "):\n",
        "\n",
        "    return max(\n",
        "        [\n",
        "            single_meteor_score(\n",
        "                reference,\n",
        "                hypothesis,\n",
        "                preprocess=preprocess,\n",
        "                stemmer=stemmer,\n",
        "                wordnet=wordnet,\n",
        "                alpha=alpha,\n",
        "                beta=beta,\n",
        "                gamma=gamma,\n",
        "            )\n",
        "            for reference in references\n",
        "        ]\n",
        "    )\n",
        "meteor_score(references,hypotheses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmcE-D8E0jxC"
      },
      "source": [
        "## **Select and Display a Single Sentence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaWFD5Jo0J5R"
      },
      "source": [
        "Word_vector=[]\n",
        "testv = testv.reshape(v_length)\n",
        "\n",
        "n=0\n",
        "m=40\n",
        "str(n)\n",
        "str(m)\n",
        "\n",
        "for i in range(9):\n",
        "  Word_vector.append(testv[n:m])\n",
        "  n=m\n",
        "  m=m+40"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X8hRuwI2WnJ"
      },
      "source": [
        "index_max=[]\n",
        "for i in range(9):\n",
        "  \n",
        "  values=np.array(Word_vector[i])\n",
        "\n",
        "  max = np.argmax(values)\n",
        "  index_max.append(max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhWAFNEyzMy2"
      },
      "source": [
        "index_max"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIGh0X_C2b4W"
      },
      "source": [
        "ptag=[]\n",
        "for x in range(9):\n",
        "  p=index_max[x]  \n",
        "  ptag.append(NewPOS_Voc[p]) \n",
        "print(ptag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqo7KJTi_wNy"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jygBEfCc6Mn-"
      },
      "source": [
        "# **Read Test Sentence and Extract Keyword**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRo4AXlMaGo-",
        "outputId": "272df2bb-be43-4d29-e0c0-70854e8e1d58"
      },
      "source": [
        "pip install yake"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting yake\n",
            "  Downloading yake-0.4.8-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[?25l\r\u001b[K     |                          | 10 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |                     | 20 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |               | 30 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |          | 40 kB 17.1 MB/s eta 0:00:01\r\u001b[K     |    | 51 kB 7.9 MB/s eta 0:00:01\r\u001b[K     || 60 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting segtok\n",
            "  Downloading segtok-1.5.10.tar.gz (25 kB)\n",
            "Collecting jellyfish\n",
            "  Downloading jellyfish-0.8.8.tar.gz (134 kB)\n",
            "\u001b[K     || 134 kB 17.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=6.0 in /usr/local/lib/python3.7/dist-packages (from yake) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from yake) (1.19.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from yake) (0.8.9)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from yake) (2.6.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from segtok->yake) (2019.12.20)\n",
            "Building wheels for collected packages: jellyfish, segtok\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.8.8-cp37-cp37m-linux_x86_64.whl size=73227 sha256=23c06b3eadef5e733a78788ff38a266c4d06eb7ad93c60c229d62f57027b164c\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/aa/f4/716387e1f167cbbf911488aa056138152f4d8699c9c9b43ea8\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-py3-none-any.whl size=25030 sha256=ed2ed13c5e1bdb25905c50ea9f1b922164c67ca544d9995ceb112f2309829ca1\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/b7/d0/a121106e61339eee5ed083bc230b1c8dc422c49a5a28c2addd\n",
            "Successfully built jellyfish segtok\n",
            "Installing collected packages: segtok, jellyfish, yake\n",
            "Successfully installed jellyfish-0.8.8 segtok-1.5.10 yake-0.4.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAKZqaZO8wuT",
        "outputId": "e967fe23-6d7e-4e20-8e92-f728c4441b9d"
      },
      "source": [
        "import yake\n",
        "kw_extractor = yake.KeywordExtractor()\n",
        "text = \"\"\"Steam forms beads of water\"\"\"\n",
        "language = \"en\"\n",
        "max_ngram_size = 1\n",
        "deduplication_threshold = 0.9\n",
        "numOfKeywords = 1\n",
        "custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, top=numOfKeywords, features=None)\n",
        "keywords = custom_kw_extractor.extract_keywords(text)\n",
        "\n",
        "Kw=[]\n",
        "for kw in keywords:\n",
        "  print(kw[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Steam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXhwNOwN6YNW"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "text = nlp(\"Steam forms beads of water\")\n",
        "dicv=[]\n",
        "dic={}\n",
        "\n",
        "for token in text: \n",
        "  t=token.tag_\n",
        "  #print(t)\n",
        "  dicv.append(t)    \n",
        "  dic[t] = token.text\n",
        "\n",
        "w=len(dicv)\n",
        "w=9-w\n",
        "#print(w)\n",
        "for c in range(w):\n",
        "  b=\"O\"\n",
        "  dicv.append(b)\n",
        "#print(dicv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSaEo23JpDg0"
      },
      "source": [
        "d=re.sub(\"[^-9A-Za-z ]\", \"\" , str(dicv))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRh98KAH4hvd"
      },
      "source": [
        "**One hot Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xwb9e81cE18"
      },
      "source": [
        "SVec=[]\n",
        "#for d in zip(dicv):#for sent in zip(z):\n",
        "token=word_tokenize(str(d))\n",
        "vectorizer = CountVectorizer(min_df=0, lowercase=False)\n",
        "vectorizer.fit(NewPOS_Voc)\n",
        "vectorizer.vocabulary_\n",
        "vectorizer.fit_transform(NewPOS_Voc)\n",
        "features=vectorizer.get_feature_names()\n",
        "\n",
        "X=vectorizer.transform(token).toarray()\n",
        "\n",
        "###############################################################\n",
        "\n",
        "v_length=360\n",
        "X = X.reshape(1,v_length)\n",
        "for i in X: \n",
        "  #print(X)\n",
        "  SVec.append(X)  \n",
        "#print(SVec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZXs3P-n4Gau",
        "outputId": "c9a8da13-48a3-4176-f031-9ab0e3bed422"
      },
      "source": [
        "SVec=np.array(SVec)\n",
        "print(SVec.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 1, 360)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUWdHOBIENag"
      },
      "source": [
        "# **End**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37wuLQy-VbDU",
        "outputId": "e1f905f2-4c12-4ffa-b248-b123302d7e83"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "text = nlp(\"volcanoes can block the sun\")\n",
        "dicv=[]\n",
        "dic={}\n",
        "\n",
        "for token in text: \n",
        "  t=token.tag_\n",
        "  dicv.append(t)    \n",
        "  dic[t] = token.text\n",
        "print(dic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'NNS': 'volcanoes', 'MD': 'can', 'VB': 'block', 'DT': 'the', 'NN': 'sun'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNqsHk8E-_Tf",
        "outputId": "67d5e791-86c7-43af-82ea-fb4b3fc682fd"
      },
      "source": [
        "def WordExtract():\n",
        "  predsent=[]\n",
        "  predtag=[]\n",
        "  tag_list=[]\n",
        "  tag_list=ptag\n",
        "  Qword=[]\n",
        "  #print(\"All Predicted tags\", ptag)\n",
        "  #print(dic)\n",
        "  p=ptag\n",
        "\n",
        "  if ((p==\"What\") or (p==\"is\") or (p==\"was\") or (p==\"type\") or (p==\"are\") or (p==\"In\") \n",
        "    or (p==\"does\") or (p==\"where\") or (p==\"do\") or (p==\"How\") or (p==\"many\") \n",
        "    or (p==\"Which\") or (p==\"When\") or (p==\"Why\") or (p==\"long\") or (p==\"part\") \n",
        "    or (p==\"of\") or (p==\"much\") or (p==\"who\") or (p==\"kind\") \n",
        "    or (p==\"keeps\") or (p==\"did\") or (p==\"Whom\") or (p==\"Whose\")):\n",
        "\n",
        "    predsent.append(p)\n",
        "    Qword.append(p)\n",
        "  elif p in dic:\n",
        "    predsent.append(dic[p])    \n",
        "    Qword.append(p)\n",
        "  else:\n",
        "    Em=\"_\"\n",
        "    predsent.append(Em)    \n",
        "    Qword.append(Em)\n",
        "  predtag=Qword\n",
        "print(\"Extracted words from the sentence=\",predsent)\n",
        "print(\"Extracted Tags from the vocabulary=\",predtag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted words from the sentence= ['type', 'does', 'much', '_', '_', '_', '_', '_', '_']\n",
            "Extracted Tags from the vocabulary= ['type', 'does', 'much', '_', '_', '_', '_', '_', '_']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGVsCK0Mc1bN",
        "outputId": "f7ca2a14-04bf-4d0f-9527-e2172626beb7"
      },
      "source": [
        "ptag=[]\n",
        "for x in range(9):\n",
        "  wt=[]\n",
        "  indv=[]\n",
        "  #k=np.array(AllPredV[x])\n",
        "  k=len(AllPredV[x])\n",
        "  print(\"\\nPredicted Word \",x)\n",
        "  for m in range(k):\n",
        "    wt=AllPredV[x]\n",
        "    indv=AllPredInx[x]\n",
        "    #print(\"indv 1\",indv)\n",
        "    print(\"\\nProbability=\",wt[m])\n",
        "    #print(\"indv\",indv[m])\n",
        "    d=indv[m]\n",
        "    str(d)\n",
        "    #print(\"d\",d)\n",
        "    ptag=NewPOS_Voc[d]\n",
        "    print(\"POS tag=\",ptag)\n",
        "    WordExtract()\n",
        "    #print(\"AllPredInx\",AllPredInx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Predicted Word  0\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP4VP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= what\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= When\n",
            "Extracted words from the sentence= ['When']\n",
            "Extracted Tags from the vocabulary= ['When']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= Which\n",
            "Extracted words from the sentence= ['Which']\n",
            "Extracted Tags from the vocabulary= ['Which']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= Why\n",
            "Extracted words from the sentence= ['Why']\n",
            "Extracted Tags from the vocabulary= ['Why']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= do\n",
            "Extracted words from the sentence= ['do']\n",
            "Extracted Tags from the vocabulary= ['do']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= does\n",
            "Extracted words from the sentence= ['does']\n",
            "Extracted Tags from the vocabulary= ['does']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= is\n",
            "Extracted words from the sentence= ['is']\n",
            "Extracted Tags from the vocabulary= ['is']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= keeps\n",
            "Extracted words from the sentence= ['keeps']\n",
            "Extracted Tags from the vocabulary= ['keeps']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= kind\n",
            "Extracted words from the sentence= ['kind']\n",
            "Extracted Tags from the vocabulary= ['kind']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= many\n",
            "Extracted words from the sentence= ['many']\n",
            "Extracted Tags from the vocabulary= ['many']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= much\n",
            "Extracted words from the sentence= ['much']\n",
            "Extracted Tags from the vocabulary= ['much']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= of\n",
            "Extracted words from the sentence= ['of']\n",
            "Extracted Tags from the vocabulary= ['of']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= part\n",
            "Extracted words from the sentence= ['part']\n",
            "Extracted Tags from the vocabulary= ['part']\n",
            "\n",
            "Probability= 0.5486288\n",
            "POS tag= type\n",
            "Extracted words from the sentence= ['type']\n",
            "Extracted Tags from the vocabulary= ['type']\n",
            "\n",
            "Probability= 0.4512407\n",
            "POS tag= where\n",
            "Extracted words from the sentence= ['where']\n",
            "Extracted Tags from the vocabulary= ['where']\n",
            "\n",
            "Probability= 0.4512088\n",
            "POS tag= who\n",
            "Extracted words from the sentence= ['who']\n",
            "Extracted Tags from the vocabulary= ['who']\n",
            "\n",
            "Predicted Word  1\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP4VP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= what\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= When\n",
            "Extracted words from the sentence= ['When']\n",
            "Extracted Tags from the vocabulary= ['When']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= Which\n",
            "Extracted words from the sentence= ['Which']\n",
            "Extracted Tags from the vocabulary= ['Which']\n",
            "\n",
            "Probability= 0.45124862\n",
            "POS tag= Why\n",
            "Extracted words from the sentence= ['Why']\n",
            "Extracted Tags from the vocabulary= ['Why']\n",
            "\n",
            "Probability= 0.45127398\n",
            "POS tag= do\n",
            "Extracted words from the sentence= ['do']\n",
            "Extracted Tags from the vocabulary= ['do']\n",
            "\n",
            "Probability= 0.45131102\n",
            "POS tag= does\n",
            "Extracted words from the sentence= ['does']\n",
            "Extracted Tags from the vocabulary= ['does']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= is\n",
            "Extracted words from the sentence= ['is']\n",
            "Extracted Tags from the vocabulary= ['is']\n",
            "\n",
            "Probability= 0.45124304\n",
            "POS tag= keeps\n",
            "Extracted words from the sentence= ['keeps']\n",
            "Extracted Tags from the vocabulary= ['keeps']\n",
            "\n",
            "Probability= 0.4512084\n",
            "POS tag= kind\n",
            "Extracted words from the sentence= ['kind']\n",
            "Extracted Tags from the vocabulary= ['kind']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= many\n",
            "Extracted words from the sentence= ['many']\n",
            "Extracted Tags from the vocabulary= ['many']\n",
            "\n",
            "Probability= 0.45120394\n",
            "POS tag= much\n",
            "Extracted words from the sentence= ['much']\n",
            "Extracted Tags from the vocabulary= ['much']\n",
            "\n",
            "Probability= 0.45121148\n",
            "POS tag= of\n",
            "Extracted words from the sentence= ['of']\n",
            "Extracted Tags from the vocabulary= ['of']\n",
            "\n",
            "Probability= 0.45125195\n",
            "POS tag= part\n",
            "Extracted words from the sentence= ['part']\n",
            "Extracted Tags from the vocabulary= ['part']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= type\n",
            "Extracted words from the sentence= ['type']\n",
            "Extracted Tags from the vocabulary= ['type']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= where\n",
            "Extracted words from the sentence= ['where']\n",
            "Extracted Tags from the vocabulary= ['where']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= who\n",
            "Extracted words from the sentence= ['who']\n",
            "Extracted Tags from the vocabulary= ['who']\n",
            "\n",
            "Predicted Word  2\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP4VP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= what\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= When\n",
            "Extracted words from the sentence= ['When']\n",
            "Extracted Tags from the vocabulary= ['When']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= Which\n",
            "Extracted words from the sentence= ['Which']\n",
            "Extracted Tags from the vocabulary= ['Which']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= Why\n",
            "Extracted words from the sentence= ['Why']\n",
            "Extracted Tags from the vocabulary= ['Why']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= do\n",
            "Extracted words from the sentence= ['do']\n",
            "Extracted Tags from the vocabulary= ['do']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= does\n",
            "Extracted words from the sentence= ['does']\n",
            "Extracted Tags from the vocabulary= ['does']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= is\n",
            "Extracted words from the sentence= ['is']\n",
            "Extracted Tags from the vocabulary= ['is']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= keeps\n",
            "Extracted words from the sentence= ['keeps']\n",
            "Extracted Tags from the vocabulary= ['keeps']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= kind\n",
            "Extracted words from the sentence= ['kind']\n",
            "Extracted Tags from the vocabulary= ['kind']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= many\n",
            "Extracted words from the sentence= ['many']\n",
            "Extracted Tags from the vocabulary= ['many']\n",
            "\n",
            "Probability= 0.4513045\n",
            "POS tag= much\n",
            "Extracted words from the sentence= ['much']\n",
            "Extracted Tags from the vocabulary= ['much']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= of\n",
            "Extracted words from the sentence= ['of']\n",
            "Extracted Tags from the vocabulary= ['of']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= part\n",
            "Extracted words from the sentence= ['part']\n",
            "Extracted Tags from the vocabulary= ['part']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= type\n",
            "Extracted words from the sentence= ['type']\n",
            "Extracted Tags from the vocabulary= ['type']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= where\n",
            "Extracted words from the sentence= ['where']\n",
            "Extracted Tags from the vocabulary= ['where']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= who\n",
            "Extracted words from the sentence= ['who']\n",
            "Extracted Tags from the vocabulary= ['who']\n",
            "\n",
            "Predicted Word  3\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP4VP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= what\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= When\n",
            "Extracted words from the sentence= ['When']\n",
            "Extracted Tags from the vocabulary= ['When']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= Which\n",
            "Extracted words from the sentence= ['Which']\n",
            "Extracted Tags from the vocabulary= ['Which']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= Why\n",
            "Extracted words from the sentence= ['Why']\n",
            "Extracted Tags from the vocabulary= ['Why']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= do\n",
            "Extracted words from the sentence= ['do']\n",
            "Extracted Tags from the vocabulary= ['do']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= does\n",
            "Extracted words from the sentence= ['does']\n",
            "Extracted Tags from the vocabulary= ['does']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= is\n",
            "Extracted words from the sentence= ['is']\n",
            "Extracted Tags from the vocabulary= ['is']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= keeps\n",
            "Extracted words from the sentence= ['keeps']\n",
            "Extracted Tags from the vocabulary= ['keeps']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= kind\n",
            "Extracted words from the sentence= ['kind']\n",
            "Extracted Tags from the vocabulary= ['kind']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= many\n",
            "Extracted words from the sentence= ['many']\n",
            "Extracted Tags from the vocabulary= ['many']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= much\n",
            "Extracted words from the sentence= ['much']\n",
            "Extracted Tags from the vocabulary= ['much']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= of\n",
            "Extracted words from the sentence= ['of']\n",
            "Extracted Tags from the vocabulary= ['of']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= part\n",
            "Extracted words from the sentence= ['part']\n",
            "Extracted Tags from the vocabulary= ['part']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= type\n",
            "Extracted words from the sentence= ['type']\n",
            "Extracted Tags from the vocabulary= ['type']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= where\n",
            "Extracted words from the sentence= ['where']\n",
            "Extracted Tags from the vocabulary= ['where']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= who\n",
            "Extracted words from the sentence= ['who']\n",
            "Extracted Tags from the vocabulary= ['who']\n",
            "\n",
            "Predicted Word  4\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP4VP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= what\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= When\n",
            "Extracted words from the sentence= ['When']\n",
            "Extracted Tags from the vocabulary= ['When']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= Which\n",
            "Extracted words from the sentence= ['Which']\n",
            "Extracted Tags from the vocabulary= ['Which']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= Why\n",
            "Extracted words from the sentence= ['Why']\n",
            "Extracted Tags from the vocabulary= ['Why']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= do\n",
            "Extracted words from the sentence= ['do']\n",
            "Extracted Tags from the vocabulary= ['do']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= does\n",
            "Extracted words from the sentence= ['does']\n",
            "Extracted Tags from the vocabulary= ['does']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= is\n",
            "Extracted words from the sentence= ['is']\n",
            "Extracted Tags from the vocabulary= ['is']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= keeps\n",
            "Extracted words from the sentence= ['keeps']\n",
            "Extracted Tags from the vocabulary= ['keeps']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= kind\n",
            "Extracted words from the sentence= ['kind']\n",
            "Extracted Tags from the vocabulary= ['kind']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= many\n",
            "Extracted words from the sentence= ['many']\n",
            "Extracted Tags from the vocabulary= ['many']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= much\n",
            "Extracted words from the sentence= ['much']\n",
            "Extracted Tags from the vocabulary= ['much']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= of\n",
            "Extracted words from the sentence= ['of']\n",
            "Extracted Tags from the vocabulary= ['of']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= part\n",
            "Extracted words from the sentence= ['part']\n",
            "Extracted Tags from the vocabulary= ['part']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= type\n",
            "Extracted words from the sentence= ['type']\n",
            "Extracted Tags from the vocabulary= ['type']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= where\n",
            "Extracted words from the sentence= ['where']\n",
            "Extracted Tags from the vocabulary= ['where']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= who\n",
            "Extracted words from the sentence= ['who']\n",
            "Extracted Tags from the vocabulary= ['who']\n",
            "\n",
            "Predicted Word  5\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP4VP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= what\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= When\n",
            "Extracted words from the sentence= ['When']\n",
            "Extracted Tags from the vocabulary= ['When']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= Which\n",
            "Extracted words from the sentence= ['Which']\n",
            "Extracted Tags from the vocabulary= ['Which']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= Why\n",
            "Extracted words from the sentence= ['Why']\n",
            "Extracted Tags from the vocabulary= ['Why']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= do\n",
            "Extracted words from the sentence= ['do']\n",
            "Extracted Tags from the vocabulary= ['do']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= does\n",
            "Extracted words from the sentence= ['does']\n",
            "Extracted Tags from the vocabulary= ['does']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= is\n",
            "Extracted words from the sentence= ['is']\n",
            "Extracted Tags from the vocabulary= ['is']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= keeps\n",
            "Extracted words from the sentence= ['keeps']\n",
            "Extracted Tags from the vocabulary= ['keeps']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= kind\n",
            "Extracted words from the sentence= ['kind']\n",
            "Extracted Tags from the vocabulary= ['kind']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= many\n",
            "Extracted words from the sentence= ['many']\n",
            "Extracted Tags from the vocabulary= ['many']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= much\n",
            "Extracted words from the sentence= ['much']\n",
            "Extracted Tags from the vocabulary= ['much']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= of\n",
            "Extracted words from the sentence= ['of']\n",
            "Extracted Tags from the vocabulary= ['of']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= part\n",
            "Extracted words from the sentence= ['part']\n",
            "Extracted Tags from the vocabulary= ['part']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= type\n",
            "Extracted words from the sentence= ['type']\n",
            "Extracted Tags from the vocabulary= ['type']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= where\n",
            "Extracted words from the sentence= ['where']\n",
            "Extracted Tags from the vocabulary= ['where']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= who\n",
            "Extracted words from the sentence= ['who']\n",
            "Extracted Tags from the vocabulary= ['who']\n",
            "\n",
            "Predicted Word  6\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP4VP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= what\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= When\n",
            "Extracted words from the sentence= ['When']\n",
            "Extracted Tags from the vocabulary= ['When']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= Which\n",
            "Extracted words from the sentence= ['Which']\n",
            "Extracted Tags from the vocabulary= ['Which']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= Why\n",
            "Extracted words from the sentence= ['Why']\n",
            "Extracted Tags from the vocabulary= ['Why']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= do\n",
            "Extracted words from the sentence= ['do']\n",
            "Extracted Tags from the vocabulary= ['do']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= does\n",
            "Extracted words from the sentence= ['does']\n",
            "Extracted Tags from the vocabulary= ['does']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= is\n",
            "Extracted words from the sentence= ['is']\n",
            "Extracted Tags from the vocabulary= ['is']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= keeps\n",
            "Extracted words from the sentence= ['keeps']\n",
            "Extracted Tags from the vocabulary= ['keeps']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= kind\n",
            "Extracted words from the sentence= ['kind']\n",
            "Extracted Tags from the vocabulary= ['kind']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= many\n",
            "Extracted words from the sentence= ['many']\n",
            "Extracted Tags from the vocabulary= ['many']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= much\n",
            "Extracted words from the sentence= ['much']\n",
            "Extracted Tags from the vocabulary= ['much']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= of\n",
            "Extracted words from the sentence= ['of']\n",
            "Extracted Tags from the vocabulary= ['of']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= part\n",
            "Extracted words from the sentence= ['part']\n",
            "Extracted Tags from the vocabulary= ['part']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= type\n",
            "Extracted words from the sentence= ['type']\n",
            "Extracted Tags from the vocabulary= ['type']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= where\n",
            "Extracted words from the sentence= ['where']\n",
            "Extracted Tags from the vocabulary= ['where']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= who\n",
            "Extracted words from the sentence= ['who']\n",
            "Extracted Tags from the vocabulary= ['who']\n",
            "\n",
            "Predicted Word  7\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP4VP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= what\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= When\n",
            "Extracted words from the sentence= ['When']\n",
            "Extracted Tags from the vocabulary= ['When']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= Which\n",
            "Extracted words from the sentence= ['Which']\n",
            "Extracted Tags from the vocabulary= ['Which']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= Why\n",
            "Extracted words from the sentence= ['Why']\n",
            "Extracted Tags from the vocabulary= ['Why']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= do\n",
            "Extracted words from the sentence= ['do']\n",
            "Extracted Tags from the vocabulary= ['do']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= does\n",
            "Extracted words from the sentence= ['does']\n",
            "Extracted Tags from the vocabulary= ['does']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= is\n",
            "Extracted words from the sentence= ['is']\n",
            "Extracted Tags from the vocabulary= ['is']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= keeps\n",
            "Extracted words from the sentence= ['keeps']\n",
            "Extracted Tags from the vocabulary= ['keeps']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= kind\n",
            "Extracted words from the sentence= ['kind']\n",
            "Extracted Tags from the vocabulary= ['kind']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= many\n",
            "Extracted words from the sentence= ['many']\n",
            "Extracted Tags from the vocabulary= ['many']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= much\n",
            "Extracted words from the sentence= ['much']\n",
            "Extracted Tags from the vocabulary= ['much']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= of\n",
            "Extracted words from the sentence= ['of']\n",
            "Extracted Tags from the vocabulary= ['of']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= part\n",
            "Extracted words from the sentence= ['part']\n",
            "Extracted Tags from the vocabulary= ['part']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= type\n",
            "Extracted words from the sentence= ['type']\n",
            "Extracted Tags from the vocabulary= ['type']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= where\n",
            "Extracted words from the sentence= ['where']\n",
            "Extracted Tags from the vocabulary= ['where']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= who\n",
            "Extracted words from the sentence= ['who']\n",
            "Extracted Tags from the vocabulary= ['who']\n",
            "\n",
            "Predicted Word  8\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP1\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP2\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP3\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= VP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP4\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP4VP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= NP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= PP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADJP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= ADVP5\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= what\n",
            "Extracted words from the sentence= ['_']\n",
            "Extracted Tags from the vocabulary= ['_']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= When\n",
            "Extracted words from the sentence= ['When']\n",
            "Extracted Tags from the vocabulary= ['When']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= Which\n",
            "Extracted words from the sentence= ['Which']\n",
            "Extracted Tags from the vocabulary= ['Which']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= Why\n",
            "Extracted words from the sentence= ['Why']\n",
            "Extracted Tags from the vocabulary= ['Why']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= do\n",
            "Extracted words from the sentence= ['do']\n",
            "Extracted Tags from the vocabulary= ['do']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= does\n",
            "Extracted words from the sentence= ['does']\n",
            "Extracted Tags from the vocabulary= ['does']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= is\n",
            "Extracted words from the sentence= ['is']\n",
            "Extracted Tags from the vocabulary= ['is']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= keeps\n",
            "Extracted words from the sentence= ['keeps']\n",
            "Extracted Tags from the vocabulary= ['keeps']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= kind\n",
            "Extracted words from the sentence= ['kind']\n",
            "Extracted Tags from the vocabulary= ['kind']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= many\n",
            "Extracted words from the sentence= ['many']\n",
            "Extracted Tags from the vocabulary= ['many']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= much\n",
            "Extracted words from the sentence= ['much']\n",
            "Extracted Tags from the vocabulary= ['much']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= of\n",
            "Extracted words from the sentence= ['of']\n",
            "Extracted Tags from the vocabulary= ['of']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= part\n",
            "Extracted words from the sentence= ['part']\n",
            "Extracted Tags from the vocabulary= ['part']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= type\n",
            "Extracted words from the sentence= ['type']\n",
            "Extracted Tags from the vocabulary= ['type']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= where\n",
            "Extracted words from the sentence= ['where']\n",
            "Extracted Tags from the vocabulary= ['where']\n",
            "\n",
            "Probability= 0.45120308\n",
            "POS tag= who\n",
            "Extracted words from the sentence= ['who']\n",
            "Extracted Tags from the vocabulary= ['who']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c7Opxk2bC8w",
        "outputId": "9e19cb20-5ac0-4c8d-af68-f796e759dffe"
      },
      "source": [
        "#Pending...\n",
        "ptag=[]\n",
        "for x in range(9):\n",
        "  p=index_max[x]  \n",
        "  ptag.append(NewPOS_Voc[p])\n",
        "print(ptag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['type', 'does', 'much', 'VP1', 'VP1', 'VP1', 'VP1', 'VP1', 'VP1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SGU6BiYk0pE",
        "outputId": "2a38eaed-1709-4e45-f706-2168fdc36e18"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "text = nlp(\"Steam forms beads of water\")\n",
        "dicv=[]\n",
        "dic={}\n",
        "\n",
        "for token in text: \n",
        "  t=token.tag_\n",
        "  dicv.append(t)    \n",
        "  dic[t] = token.text\n",
        "print(dic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'NN': 'water', 'VBZ': 'forms', 'NNS': 'beads', 'IN': 'of'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFEnFB6NgHW7",
        "outputId": "9e3dc09e-02e0-4d71-f01e-075fd975d342"
      },
      "source": [
        "#def WordExtract():\n",
        "predsent=[]\n",
        "predtag=[]\n",
        "tag_list=[]\n",
        "tag_list=ptag\n",
        "Qword=[]\n",
        "print(\"All Predicted tags\", ptag)\n",
        "print(dic)\n",
        "for t in range(9):\n",
        "  p=ptag[t]\n",
        "\n",
        "  if ((p==\"What\") or (p==\"is\") or (p==\"was\") or (p==\"type\") or (p==\"are\") or (p==\"In\") \n",
        "    or (p==\"does\") or (p==\"where\") or (p==\"do\") or (p==\"How\") or (p==\"many\") \n",
        "    or (p==\"Which\") or (p==\"When\") or (p==\"Why\") or (p==\"long\") or (p==\"part\") \n",
        "    or (p==\"of\") or (p==\"much\") or (p==\"who\") or (p==\"kind\") \n",
        "    or (p==\"keeps\") or (p==\"did\") or (p==\"Whom\") or (p==\"Whose\")):\n",
        "\n",
        "    predsent.append(p)\n",
        "    Qword.append(p)\n",
        "  elif p in dic:\n",
        "    predsent.append(dic[p])    \n",
        "    Qword.append(p)\n",
        "  else:\n",
        "    Em=\"_\"\n",
        "    predsent.append(Em)    \n",
        "    Qword.append(Em)\n",
        "predtag=Qword\n",
        "print(\"\\nPredicted words=\",predsent)\n",
        "print(\"\\nAll predicted words extracted Tags from the sentence\\n\",predtag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All Predicted tags ['type', 'does', 'much', 'VP1', 'VP1', 'VP1', 'VP1', 'VP1', 'VP1']\n",
            "{'NN': 'water', 'VBZ': 'forms', 'NNS': 'beads', 'IN': 'of'}\n",
            "\n",
            "Predicted words= ['type', 'does', 'much', '_', '_', '_', '_', '_', '_']\n",
            "\n",
            "All predicted words extracted Tags from the sentence\n",
            " ['type', 'does', 'much', '_', '_', '_', '_', '_', '_']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "BOfMdRPfMH8R",
        "outputId": "c8d68550-6b9e-49c1-f1fc-1f8b4ec38c36"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist.history['accuracy'], label='train') \n",
        "plt.plot(hist.history['val_accuracy'], label='test')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "914kvkThMNqo"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "reference = [\n",
        "    'What is comment statement'.split(),\n",
        "    'What is Charles Babbage'.split(),\n",
        "    'What is web servers'.split(),\n",
        "    'What is network model'.split() \n",
        "]\n",
        "candidate = 'What does do'.split()\n",
        "print('BLEU score -> {}'.format(sentence_bleu(reference, candidate )))\n",
        " \n",
        "candidate = 'What Charles does do'.split()\n",
        "print('BLEU score -> {}'.format(sentence_bleu(reference, candidate)))\n",
        "\n",
        "candidate = 'What is database system'.split()\n",
        "print('BLEU score -> {}'.format(sentence_bleu(reference, candidate )))\n",
        " \n",
        "candidate = 'What is securtiy'.split()\n",
        "print('BLEU score -> {}'.format(sentence_bleu(reference, candidate)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}